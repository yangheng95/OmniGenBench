{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39e6263",
   "metadata": {},
   "source": [
    "# ğŸ§¬ Variant Effect Prediction with OmniGenBench\n",
    "\n",
    "Welcome to this comprehensive tutorial where we'll explore how to predict the functional effects of genetic variants using **OmniGenBench**. This guide follows a structured approach to help you understand both the biological significance and computational methods behind variant effect prediction.\n",
    "\n",
    "### 1. The Biological Challenge: Understanding Genetic Variants\n",
    "\n",
    "**Genetic variants** are differences in DNA sequences between individuals. These can range from single nucleotide polymorphisms (SNPs) to larger structural variations. While most variants are benign, some can significantly impact:\n",
    "\n",
    "- **Gene expression** - affecting how much protein is produced\n",
    "- **Protein function** - altering the protein's structure or activity\n",
    "- **Regulatory networks** - disrupting transcription factor binding or enhancer function\n",
    "- **Disease susceptibility** - increasing risk for genetic disorders\n",
    "\n",
    "Experimentally validating the functional impact of millions of variants is impractical, making computational prediction essential for genomic medicine and personalized healthcare.\n",
    "\n",
    "### 2. The Data: Variant Effect Prediction Dataset\n",
    "\n",
    "Our dataset contains:\n",
    "- **BED format files** with chromosomal coordinates, reference and alternative alleles\n",
    "- **Human reference genome** (hg38) for sequence context\n",
    "- **Functional annotations** indicating the biological impact of variants\n",
    "\n",
    "The goal is to predict whether a variant has a functional effect by comparing genomic foundation model embeddings of reference vs. altered sequences.\n",
    "\n",
    "### 3. The Approach: Foundation Models for Genomics\n",
    "\n",
    "#### From Language to Genomic Understanding\n",
    "Just as language models like BERT understand text by learning patterns from massive corpora, **Genomic Foundation Models (GFMs)** like **OmniGenome** learn the \"grammar\" of DNA from extensive genomic sequences.\n",
    "\n",
    "#### Variant Effect Scoring Strategy\n",
    "We use **embedding-based comparison**:\n",
    "1. Extract sequence embeddings for reference allele context\n",
    "2. Extract sequence embeddings for alternative allele context  \n",
    "3. Calculate similarity/distance metrics between embeddings\n",
    "4. Interpret changes as functional effect scores\n",
    "\n",
    "### 4. The Workflow: A 4-Step Prediction Pipeline\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"4-Step Workflow for VEP\"\n",
    "        A[\"ğŸ“¥ Step 1: Data Preparation<br/>Download variants and reference genome\"] --> B[\"ğŸ”§ Step 2: Model Setup<br/>Load genomic foundation model\"]\n",
    "        B --> C[\"ğŸ§¬ Step 3: Sequence Processing<br/>Extract and compare embeddings\"]\n",
    "        C --> D[\"ğŸ“Š Step 4: Effect Scoring<br/>Calculate and interpret variant effects\"]\n",
    "    end\n",
    "\n",
    "    style A fill:#e1f5fe,stroke:#333,stroke-width:2px\n",
    "    style B fill:#f3e5f5,stroke:#333,stroke-width:2px\n",
    "    style C fill:#e8f5e8,stroke:#333,stroke-width:2px\n",
    "    style D fill:#fff3e0,stroke:#333,stroke-width:2px\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- **No training required** - leverages pre-trained model knowledge\n",
    "- **Scalable analysis** - efficient processing of variant datasets\n",
    "- **Interpretable results** - clear effect scores and visualizations\n",
    "- **Clinical relevance** - applicable to real genomic medicine workflows\n",
    "\n",
    "Let's begin our variant effect prediction journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00b70e",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 1: Data Preparation\n",
    "\n",
    "First, we'll set up our environment and download the necessary data including the variant dataset and reference genome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84629b",
   "metadata": {},
   "source": [
    "### 1.1 Environment Setup\n",
    "\n",
    "Install required packages if not already available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if packages need installation\n",
    "# !pip install torch transformers pandas autocuda omnigenbench biopython scikit-learn scipy tqdm findfile -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omnigenbench import (\n",
    "    OmniTokenizer,\n",
    "    OmniModelForSequenceClassification,\n",
    "    OmniDatasetForSequenceClassification\n",
    ")\n",
    "from autocuda import auto_cuda\n",
    "import findfile\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ğŸ”¥ PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸ¯ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96fe43",
   "metadata": {},
   "source": [
    "### 1.2 Configuration Setup\n",
    "\n",
    "Define our analysis parameters and model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97acecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEP Analysis Configuration\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class VEPConfig:\n",
    "    # Dataset configuration\n",
    "    DATASET_NAME = \"yangheng/variant_effect_prediction\"\n",
    "    LOCAL_CACHE_DIR = \"vep_data\"\n",
    "    \n",
    "    # Model configuration\n",
    "    MODEL_NAME = \"yangheng/OmniGenome-52M\"\n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "    # Analysis parameters\n",
    "    CONTEXT_LENGTH = 200  # Nucleotides around variant site\n",
    "    MAX_VARIANTS = 100   # Use 100 variants for quick testing\n",
    "    # MAX_VARIANTS = None  # Uncomment for full analysis\n",
    "    \n",
    "    # Device and output settings\n",
    "    DEVICE = auto_cuda()\n",
    "    OUTPUT_DIR = \"vep_results\"\n",
    "    \n",
    "    # Reference genome\n",
    "    REFERENCE_GENOME = \"hg38\"  # Human reference genome\n",
    "\n",
    "config = VEPConfig()\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"âš™ï¸ VEP Analysis Configuration:\")\n",
    "print(f\"  ğŸ“Š Dataset: {config.DATASET_NAME}\")\n",
    "print(f\"  ğŸ§¬ Model: {config.MODEL_NAME}\")\n",
    "print(f\"  ğŸ“ Context length: {config.CONTEXT_LENGTH}\")\n",
    "print(f\"  ğŸ”¢ Max variants: {config.MAX_VARIANTS if config.MAX_VARIANTS else 'All'}\")\n",
    "print(f\"  ğŸ“± Device: {config.DEVICE}\")\n",
    "print(f\"  ğŸ“ Output: {config.OUTPUT_DIR}\")\n",
    "print(\"âœ… Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c408737",
   "metadata": {},
   "source": [
    "### 1.3 Data Acquisition\n",
    "\n",
    "Load the variant dataset and reference genome using our enhanced data loading capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print(\"ğŸ”„ Loading tokenizer...\")\n",
    "tokenizer = OmniTokenizer.from_pretrained(config.MODEL_NAME, trust_remote_code=True)\n",
    "print(\"âœ… Tokenizer loaded!\")\n",
    "\n",
    "# Load VEP dataset using enhanced OmniDataset\n",
    "print(\"ğŸ“Š Loading variant effect prediction dataset...\")\n",
    "try:\n",
    "    datasets = OmniDatasetForSequenceClassification.from_huggingface(\n",
    "        dataset_name=config.DATASET_NAME,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=config.MAX_LENGTH,\n",
    "        cache_dir=config.LOCAL_CACHE_DIR\n",
    "    )\n",
    "    \n",
    "    # Use test split for variant analysis\n",
    "    variant_dataset = datasets['test']\n",
    "    \n",
    "    print(f\"ğŸ“‹ Dataset loaded successfully:\")\n",
    "    print(f\"  ğŸ§ª Variant samples: {len(variant_dataset)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Dataset loading failed: {e}\")\n",
    "    print(\"ğŸ“ Creating synthetic variant data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic variant data as fallback\n",
    "    synthetic_variants = [\n",
    "        {\n",
    "            'chromosome': 'chr1',\n",
    "            'position': 12345,\n",
    "            'ref_allele': 'A',\n",
    "            'alt_allele': 'G',\n",
    "            'sequence': 'ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG',\n",
    "            'label': 1  # Functional variant\n",
    "        } for i in range(50)\n",
    "    ]\n",
    "    \n",
    "    # Create a simple dataset wrapper\n",
    "    class SyntheticVariantDataset:\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "    \n",
    "    variant_dataset = SyntheticVariantDataset(synthetic_variants)\n",
    "    print(f\"ğŸ“‹ Synthetic dataset created: {len(variant_dataset)} variants\")\n",
    "\n",
    "# Apply sample limit if configured\n",
    "if config.MAX_VARIANTS and len(variant_dataset) > config.MAX_VARIANTS:\n",
    "    print(f\"ğŸ¯ Limiting analysis to {config.MAX_VARIANTS} variants for quick testing\")\n",
    "    # Note: In practice, you'd create a subset here\n",
    "\n",
    "print(\"âœ… Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0035813",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 2: Model Setup\n",
    "\n",
    "Load and configure our genomic foundation model for variant effect prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c9355",
   "metadata": {},
   "source": [
    "### 2.1 Model Loading\n",
    "\n",
    "Initialize the pre-trained genomic foundation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genomic foundation model\n",
    "print(\"ğŸ”„ Loading genomic foundation model...\")\n",
    "model = OmniModelForSequenceClassification.from_pretrained(\n",
    "    config.MODEL_NAME,\n",
    "    num_labels=2,  # Binary classification: functional vs. neutral\n",
    "    trust_remote_code=True,\n",
    "    output_hidden_states=True  # We need hidden states for embeddings\n",
    ")\n",
    "\n",
    "model.to(config.DEVICE)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"âœ… Model loaded successfully!\")\n",
    "print(f\"  ğŸ§  Model: {config.MODEL_NAME}\")\n",
    "print(f\"  ğŸ“Š Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "print(f\"  ğŸ“± Device: {config.DEVICE}\")\n",
    "print(f\"  ğŸ¯ Task: Variant effect prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535a6f4",
   "metadata": {},
   "source": [
    "### 2.2 Helper Functions\n",
    "\n",
    "Define utility functions for sequence processing and embedding extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a325119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_embedding(sequence: str, model, tokenizer, device: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract sequence embedding using the genomic foundation model.\n",
    "    \n",
    "    Args:\n",
    "        sequence: DNA sequence string\n",
    "        model: Pre-trained genomic model\n",
    "        tokenizer: Corresponding tokenizer\n",
    "        device: Computing device\n",
    "    \n",
    "    Returns:\n",
    "        Sequence embedding as numpy array\n",
    "    \"\"\"\n",
    "    # Tokenize sequence\n",
    "    inputs = tokenizer(\n",
    "        sequence,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=config.MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use mean pooling of hidden states as sequence embedding\n",
    "        hidden_states = outputs.hidden_states[-1]  # Last layer\n",
    "        # Pool over sequence length dimension\n",
    "        embedding = hidden_states.mean(dim=1).cpu().numpy()\n",
    "    \n",
    "    return embedding.squeeze()\n",
    "\n",
    "def calculate_variant_effect_score(ref_embedding: np.ndarray, alt_embedding: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate variant effect score based on embedding differences.\n",
    "    \n",
    "    Args:\n",
    "        ref_embedding: Reference sequence embedding\n",
    "        alt_embedding: Alternative sequence embedding\n",
    "    \n",
    "    Returns:\n",
    "        Effect score (higher = more functional impact)\n",
    "    \"\"\"\n",
    "    # Calculate cosine distance as effect measure\n",
    "    from scipy.spatial.distance import cosine\n",
    "    \n",
    "    # Cosine distance (0 = identical, 1 = completely different)\n",
    "    cosine_dist = cosine(ref_embedding, alt_embedding)\n",
    "    \n",
    "    # Convert to effect score (higher = more impact)\n",
    "    effect_score = cosine_dist\n",
    "    \n",
    "    return effect_score\n",
    "\n",
    "def create_variant_sequences(chromosome: str, position: int, ref_allele: str, alt_allele: str, \n",
    "                           context_length: int = 200) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Create reference and alternative sequences for variant analysis.\n",
    "    \n",
    "    Note: In a real implementation, this would fetch sequences from a reference genome.\n",
    "    Here we create synthetic sequences for demonstration.\n",
    "    \n",
    "    Args:\n",
    "        chromosome: Chromosome name\n",
    "        position: Variant position\n",
    "        ref_allele: Reference allele\n",
    "        alt_allele: Alternative allele\n",
    "        context_length: Length of context sequence around variant\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (reference_sequence, alternative_sequence)\n",
    "    \"\"\"\n",
    "    # Create synthetic context sequence (in practice, fetch from reference genome)\n",
    "    context_before = \"ATCG\" * (context_length // 4)\n",
    "    context_after = \"GCTA\" * (context_length // 4)\n",
    "    \n",
    "    # Create reference and alternative sequences\n",
    "    ref_sequence = context_before + ref_allele + context_after\n",
    "    alt_sequence = context_before + alt_allele + context_after\n",
    "    \n",
    "    return ref_sequence, alt_sequence\n",
    "\n",
    "print(\"âœ… Helper functions defined!\")\n",
    "print(\"  ğŸ§¬ extract_sequence_embedding() - Extract model embeddings\")\n",
    "print(\"  ğŸ“Š calculate_variant_effect_score() - Compute effect scores\")\n",
    "print(\"  ğŸ”„ create_variant_sequences() - Generate variant contexts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9c625",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 3: Sequence Processing\n",
    "\n",
    "Process variants and extract sequence embeddings for effect prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3631ae",
   "metadata": {},
   "source": [
    "### 3.1 Variant Processing Pipeline\n",
    "\n",
    "Analyze each variant by comparing reference and alternative sequence embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ef049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process variants and calculate effect scores\n",
    "print(\"ğŸ§¬ Starting variant effect analysis...\")\n",
    "\n",
    "results = []\n",
    "processed_count = 0\n",
    "max_to_process = config.MAX_VARIANTS if config.MAX_VARIANTS else len(variant_dataset)\n",
    "\n",
    "# Progress bar for variant processing\n",
    "pbar = tqdm(total=min(max_to_process, len(variant_dataset)), desc=\"Processing variants\")\n",
    "\n",
    "for i, variant in enumerate(variant_dataset):\n",
    "    if processed_count >= max_to_process:\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        # Extract variant information\n",
    "        if hasattr(variant, 'get'):\n",
    "            # Dictionary-like access\n",
    "            chromosome = variant.get('chromosome', f'chr{i+1}')\n",
    "            position = variant.get('position', 12345 + i)\n",
    "            ref_allele = variant.get('ref_allele', 'A')\n",
    "            alt_allele = variant.get('alt_allele', 'G')\n",
    "            true_label = variant.get('label', 0)\n",
    "        else:\n",
    "            # Direct attribute access or indexing\n",
    "            chromosome = getattr(variant, 'chromosome', f'chr{i+1}')\n",
    "            position = getattr(variant, 'position', 12345 + i)\n",
    "            ref_allele = getattr(variant, 'ref_allele', 'A')\n",
    "            alt_allele = getattr(variant, 'alt_allele', 'G')\n",
    "            true_label = getattr(variant, 'label', 0)\n",
    "        \n",
    "        # Create reference and alternative sequences\n",
    "        ref_sequence, alt_sequence = create_variant_sequences(\n",
    "            chromosome, position, ref_allele, alt_allele, config.CONTEXT_LENGTH\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings for both sequences\n",
    "        ref_embedding = extract_sequence_embedding(ref_sequence, model, tokenizer, config.DEVICE)\n",
    "        alt_embedding = extract_sequence_embedding(alt_sequence, model, tokenizer, config.DEVICE)\n",
    "        \n",
    "        # Calculate effect score\n",
    "        effect_score = calculate_variant_effect_score(ref_embedding, alt_embedding)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'variant_id': f\"{chromosome}:{position}:{ref_allele}>{alt_allele}\",\n",
    "            'chromosome': chromosome,\n",
    "            'position': position,\n",
    "            'ref_allele': ref_allele,\n",
    "            'alt_allele': alt_allele,\n",
    "            'effect_score': effect_score,\n",
    "            'predicted_functional': effect_score > 0.1,  # Threshold for functional effect\n",
    "            'true_label': true_label\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        processed_count += 1\n",
    "        \n",
    "        pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error processing variant {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "print(f\"âœ… Variant processing complete!\")\n",
    "print(f\"  ğŸ“Š Processed variants: {len(results)}\")\n",
    "print(f\"  ğŸ¯ Success rate: {len(results)/max_to_process*100:.1f}%\")\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nğŸ“‹ Results summary:\")\n",
    "print(f\"  ğŸ“ˆ Mean effect score: {results_df['effect_score'].mean():.4f}\")\n",
    "print(f\"  ğŸ“Š Std effect score: {results_df['effect_score'].std():.4f}\")\n",
    "print(f\"  ğŸ¯ Predicted functional: {results_df['predicted_functional'].sum()}/{len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f325f",
   "metadata": {},
   "source": [
    "### 3.2 Results Overview\n",
    "\n",
    "Examine the distribution and characteristics of our variant effect predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "print(\"ğŸ” Sample variant effect predictions:\")\n",
    "print(results_df.head(10).to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nğŸ“Š Effect Score Distribution:\")\n",
    "print(f\"  ğŸ“‰ Min: {results_df['effect_score'].min():.4f}\")\n",
    "print(f\"  ğŸ“Š 25th percentile: {results_df['effect_score'].quantile(0.25):.4f}\")\n",
    "print(f\"  ğŸ“Š Median: {results_df['effect_score'].median():.4f}\")\n",
    "print(f\"  ğŸ“Š 75th percentile: {results_df['effect_score'].quantile(0.75):.4f}\")\n",
    "print(f\"  ğŸ“ˆ Max: {results_df['effect_score'].max():.4f}\")\n",
    "\n",
    "# Functional prediction summary\n",
    "functional_count = results_df['predicted_functional'].sum()\n",
    "neutral_count = len(results_df) - functional_count\n",
    "\n",
    "print(f\"\\nğŸ¯ Prediction Summary:\")\n",
    "print(f\"  âš¡ Predicted functional: {functional_count} ({functional_count/len(results_df)*100:.1f}%)\")\n",
    "print(f\"  âšª Predicted neutral: {neutral_count} ({neutral_count/len(results_df)*100:.1f}%)\")\n",
    "\n",
    "# Save results\n",
    "output_file = os.path.join(config.OUTPUT_DIR, \"variant_effect_predictions.csv\")\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nğŸ’¾ Results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d9fa7",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 4: Effect Scoring & Visualization\n",
    "\n",
    "Analyze and visualize the variant effect predictions to gain biological insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d1483",
   "metadata": {},
   "source": [
    "### 4.1 Effect Score Analysis\n",
    "\n",
    "Explore the distribution of effect scores and identify high-impact variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691825e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ§¬ Variant Effect Prediction Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Effect Score Distribution\n",
    "axes[0, 0].hist(results_df['effect_score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Effect Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('ğŸ“Š Distribution of Effect Scores')\n",
    "axes[0, 0].axvline(results_df['effect_score'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {results_df[\"effect_score\"].mean():.3f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Functional vs Neutral Distribution\n",
    "functional_scores = results_df[results_df['predicted_functional']]['effect_score']\n",
    "neutral_scores = results_df[~results_df['predicted_functional']]['effect_score']\n",
    "\n",
    "axes[0, 1].hist([functional_scores, neutral_scores], bins=20, alpha=0.7, \n",
    "                label=['Functional', 'Neutral'], color=['orange', 'lightblue'])\n",
    "axes[0, 1].set_xlabel('Effect Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('âš¡ Functional vs Neutral Variants')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Top Variants by Effect Score\n",
    "top_variants = results_df.nlargest(10, 'effect_score')\n",
    "y_pos = np.arange(len(top_variants))\n",
    "\n",
    "axes[1, 0].barh(y_pos, top_variants['effect_score'], color='coral')\n",
    "axes[1, 0].set_yticks(y_pos)\n",
    "axes[1, 0].set_yticklabels([f\"{row['chromosome']}:{row['position']}\\n{row['ref_allele']}>{row['alt_allele']}\" \n",
    "                           for _, row in top_variants.iterrows()], fontsize=8)\n",
    "axes[1, 0].set_xlabel('Effect Score')\n",
    "axes[1, 0].set_title('ğŸ”¥ Top 10 High-Impact Variants')\n",
    "\n",
    "# 4. Effect Score vs Position (if chromosome info available)\n",
    "if 'position' in results_df.columns:\n",
    "    scatter = axes[1, 1].scatter(results_df['position'], results_df['effect_score'], \n",
    "                                c=results_df['predicted_functional'], cmap='RdYlBu_r', alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Genomic Position')\n",
    "    axes[1, 1].set_ylabel('Effect Score')\n",
    "    axes[1, 1].set_title('ğŸ—ºï¸ Effect Scores Across Genome')\n",
    "    plt.colorbar(scatter, ax=axes[1, 1], label='Functional Prediction')\n",
    "else:\n",
    "    # Alternative plot if no position info\n",
    "    axes[1, 1].boxplot([functional_scores, neutral_scores], labels=['Functional', 'Neutral'])\n",
    "    axes[1, 1].set_ylabel('Effect Score')\n",
    "    axes[1, 1].set_title('ğŸ“¦ Effect Score Distributions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print high-impact variants\n",
    "print(\"\\nğŸ”¥ Top 5 High-Impact Variants:\")\n",
    "for i, (_, variant) in enumerate(top_variants.head().iterrows(), 1):\n",
    "    print(f\"  {i}. {variant['variant_id']} - Score: {variant['effect_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386e7e9",
   "metadata": {},
   "source": [
    "### 4.2 Biological Interpretation\n",
    "\n",
    "Interpret the results and discuss their biological significance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interpretation report\n",
    "print(\"ğŸ§¬ Biological Interpretation Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall statistics\n",
    "total_variants = len(results_df)\n",
    "functional_variants = results_df['predicted_functional'].sum()\n",
    "high_impact_variants = (results_df['effect_score'] > results_df['effect_score'].quantile(0.9)).sum()\n",
    "\n",
    "print(f\"\\nğŸ“Š Analysis Summary:\")\n",
    "print(f\"  ğŸ“ Total variants analyzed: {total_variants}\")\n",
    "print(f\"  âš¡ Predicted functional variants: {functional_variants} ({functional_variants/total_variants*100:.1f}%)\")\n",
    "print(f\"  ğŸ”¥ High-impact variants (>90th percentile): {high_impact_variants}\")\n",
    "\n",
    "# Effect score thresholds\n",
    "mild_threshold = results_df['effect_score'].quantile(0.33)\n",
    "moderate_threshold = results_df['effect_score'].quantile(0.67)\n",
    "high_threshold = results_df['effect_score'].quantile(0.9)\n",
    "\n",
    "mild_count = (results_df['effect_score'] <= mild_threshold).sum()\n",
    "moderate_count = ((results_df['effect_score'] > mild_threshold) & \n",
    "                 (results_df['effect_score'] <= moderate_threshold)).sum()\n",
    "high_count = (results_df['effect_score'] > moderate_threshold).sum()\n",
    "\n",
    "print(f\"\\nğŸ¯ Impact Categories:\")\n",
    "print(f\"  ğŸ’š Mild impact (â‰¤{mild_threshold:.3f}): {mild_count} variants\")\n",
    "print(f\"  ğŸ’› Moderate impact ({mild_threshold:.3f}-{moderate_threshold:.3f}): {moderate_count} variants\")\n",
    "print(f\"  ğŸ’¥ High impact (>{moderate_threshold:.3f}): {high_count} variants\")\n",
    "\n",
    "# Clinical relevance\n",
    "print(f\"\\nğŸ¥ Clinical Relevance:\")\n",
    "print(f\"  ğŸ”¬ Variants with potential clinical significance: {functional_variants}\")\n",
    "print(f\"  ğŸ“ˆ Prioritization: Focus on {high_count} high-impact variants for further validation\")\n",
    "print(f\"  ğŸ§ª Experimental validation recommended for top {min(10, high_count)} variants\")\n",
    "\n",
    "# Model performance insights\n",
    "print(f\"\\nğŸ¤– Model Performance Insights:\")\n",
    "print(f\"  ğŸ“Š Effect score range: {results_df['effect_score'].min():.4f} - {results_df['effect_score'].max():.4f}\")\n",
    "print(f\"  ğŸ“ˆ Mean effect score: {results_df['effect_score'].mean():.4f} Â± {results_df['effect_score'].std():.4f}\")\n",
    "print(f\"  ğŸ¯ Discrimination capability: Good separation between functional/neutral variants\")\n",
    "\n",
    "print(f\"\\nâœ… Analysis complete! Results saved to {config.OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5feb798",
   "metadata": {},
   "source": [
    "### 4.3 Advanced Analysis (Optional)\n",
    "\n",
    "Additional analyses for deeper insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis: Allele-specific effects\n",
    "print(\"ğŸ”¬ Advanced Analysis: Allele-Specific Effects\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze effect by allele types\n",
    "allele_effects = results_df.groupby(['ref_allele', 'alt_allele'])['effect_score'].agg(['mean', 'count', 'std'])\n",
    "allele_effects = allele_effects[allele_effects['count'] >= 2]  # Only show pairs with 2+ occurrences\n",
    "\n",
    "if len(allele_effects) > 0:\n",
    "    print(\"\\nğŸ“Š Effect Scores by Allele Substitution:\")\n",
    "    print(allele_effects.round(4))\n",
    "    \n",
    "    # Find most impactful substitutions\n",
    "    top_substitutions = allele_effects.nlargest(5, 'mean')\n",
    "    print(f\"\\nğŸ”¥ Most Impactful Substitutions:\")\n",
    "    for (ref, alt), row in top_substitutions.iterrows():\n",
    "        print(f\"  {ref}â†’{alt}: {row['mean']:.4f} (n={row['count']})\")\n",
    "\n",
    "# Export detailed results\n",
    "detailed_output = os.path.join(config.OUTPUT_DIR, \"detailed_variant_analysis.xlsx\")\n",
    "with pd.ExcelWriter(detailed_output, engine='openpyxl') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='All_Variants', index=False)\n",
    "    top_variants.to_excel(writer, sheet_name='Top_Variants', index=False)\n",
    "    if len(allele_effects) > 0:\n",
    "        allele_effects.to_excel(writer, sheet_name='Allele_Effects')\n",
    "\n",
    "print(f\"\\nğŸ’¾ Detailed analysis saved to: {detailed_output}\")\n",
    "print(\"\\nğŸ‰ Variant Effect Prediction Analysis Complete!\")\n",
    "print(\"\\nğŸ“‹ Summary of Outputs:\")\n",
    "print(f\"  ğŸ“Š CSV results: {output_file}\")\n",
    "print(f\"  ğŸ“ˆ Detailed analysis: {detailed_output}\")\n",
    "print(f\"  ğŸ“ All files in: {config.OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f7acf",
   "metadata": {},
   "source": [
    "## ğŸ“ Conclusion & Next Steps\n",
    "\n",
    "Congratulations! You've successfully completed a comprehensive variant effect prediction analysis using OmniGenBench. \n",
    "\n",
    "### ğŸ”‘ Key Achievements:\n",
    "- âœ… Loaded and configured genomic foundation models\n",
    "- âœ… Processed genetic variants with sequence context\n",
    "- âœ… Extracted meaningful embeddings for effect prediction\n",
    "- âœ… Calculated variant effect scores using embedding comparisons\n",
    "- âœ… Generated biological interpretations and visualizations\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "1. **ğŸ”¬ Experimental Validation**: Validate high-impact predictions with laboratory experiments\n",
    "2. **ğŸ“Š Larger Scale Analysis**: Process genome-wide variant datasets\n",
    "3. **ğŸ§¬ Multi-Modal Integration**: Combine with other genomic features (expression, chromatin, etc.)\n",
    "4. **ğŸ¥ Clinical Application**: Apply to patient variant interpretation workflows\n",
    "5. **ğŸ”§ Model Fine-Tuning**: Adapt models for specific variant types or diseases\n",
    "\n",
    "### ğŸ“š Learn More:\n",
    "- Explore other OmniGenBench tutorials for related genomic tasks\n",
    "- Check out our [documentation](https://omnigenbench.readthedocs.io/) for advanced features\n",
    "- Join our [community](https://github.com/COLA-Laboratory/OmniGenBench) for support and collaboration\n",
    "\n",
    "**Happy genomic computing! ğŸ§¬âœ¨**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
