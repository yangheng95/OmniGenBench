{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04dd3ec",
   "metadata": {},
   "source": [
    "# ğŸ“Š VEP Visualization and Export Tutorial\n",
    "\n",
    "This tutorial focuses on creating comprehensive visualizations and exporting results from Variant Effect Prediction (VEP) analysis using OmniGenBench.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we'll explore:\n",
    "- Advanced visualization techniques for variant effect analysis\n",
    "- Statistical analysis and interpretation of results\n",
    "- Multiple export formats for downstream analysis\n",
    "- Publication-ready plots and reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ebe9a",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's set up our environment and load sample VEP results for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization and analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from typing import Dict, List, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… Visualization libraries imported successfully!\")\n",
    "print(\"ğŸ“Š Ready for VEP result analysis and visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7001dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample VEP results for demonstration\n",
    "# In practice, this would be loaded from previous analysis\n",
    "def create_sample_vep_data(n_variants: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create sample VEP analysis results for demonstration.\n",
    "    \n",
    "    Args:\n",
    "        n_variants: Number of variants to simulate\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with VEP analysis results\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducible results\n",
    "    \n",
    "    # Variant types and their properties\n",
    "    variant_types = ['SNV_transition', 'SNV_transversion', 'insertion', 'deletion']\n",
    "    chromosomes = [f'chr{i}' for i in range(1, 23)] + ['chrX', 'chrY']\n",
    "    \n",
    "    data = []\n",
    "    for i in range(n_variants):\n",
    "        # Generate variant properties\n",
    "        var_type = np.random.choice(variant_types)\n",
    "        chromosome = np.random.choice(chromosomes)\n",
    "        position = np.random.randint(1000000, 250000000)\n",
    "        \n",
    "        # Generate realistic effect scores based on variant type\n",
    "        if var_type.startswith('SNV'):\n",
    "            base_score = np.random.beta(2, 8)  # Most SNVs have low effect\n",
    "            if 'transition' in var_type:\n",
    "                base_score *= 0.8  # Transitions generally less disruptive\n",
    "        else:  # INDELs\n",
    "            base_score = np.random.beta(3, 5)  # INDELs more likely to be functional\n",
    "        \n",
    "        # Add some noise and ensure realistic ranges\n",
    "        cosine_score = np.clip(base_score + np.random.normal(0, 0.05), 0, 1)\n",
    "        euclidean_score = cosine_score * np.random.uniform(10, 100)  # Scale appropriately\n",
    "        manhattan_score = cosine_score * np.random.uniform(50, 500)\n",
    "        \n",
    "        # Generate functional prediction based on threshold\n",
    "        threshold = 0.15\n",
    "        predicted_functional = cosine_score > threshold\n",
    "        \n",
    "        # Generate confidence and additional metrics\n",
    "        confidence = np.random.uniform(0.6, 0.95) if predicted_functional else np.random.uniform(0.3, 0.7)\n",
    "        \n",
    "        # Simulate true labels (with some noise for realistic scenarios)\n",
    "        true_functional = predicted_functional\n",
    "        if np.random.random() < 0.1:  # 10% label noise\n",
    "            true_functional = not true_functional\n",
    "        \n",
    "        data.append({\n",
    "            'variant_id': f'var_{i+1}',\n",
    "            'chromosome': chromosome,\n",
    "            'position': position,\n",
    "            'variant_type': var_type,\n",
    "            'ref_allele': np.random.choice(['A', 'T', 'G', 'C']),\n",
    "            'alt_allele': np.random.choice(['A', 'T', 'G', 'C']),\n",
    "            'cosine_score': cosine_score,\n",
    "            'euclidean_score': euclidean_score,\n",
    "            'manhattan_score': manhattan_score,\n",
    "            'predicted_functional': predicted_functional,\n",
    "            'true_functional': true_functional,\n",
    "            'confidence': confidence,\n",
    "            'genomic_region': np.random.choice(['exonic', 'intronic', 'intergenic', 'promoter', 'UTR']),\n",
    "            'population_frequency': np.random.exponential(0.01),  # Most variants are rare\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate sample data\n",
    "vep_results = create_sample_vep_data(200)\n",
    "\n",
    "print(f\"ğŸ“Š Sample VEP Dataset Created:\")\n",
    "print(f\"  ğŸ§¬ Total variants: {len(vep_results)}\")\n",
    "print(f\"  âš¡ Predicted functional: {vep_results['predicted_functional'].sum()}\")\n",
    "print(f\"  ğŸ“ˆ Mean cosine score: {vep_results['cosine_score'].mean():.4f}\")\n",
    "print(f\"  ğŸ¯ Variant types: {vep_results['variant_type'].value_counts().to_dict()}\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nğŸ” Sample data preview:\")\n",
    "print(vep_results.head()[['variant_id', 'variant_type', 'cosine_score', 'predicted_functional']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc09bc1",
   "metadata": {},
   "source": [
    "## 2. Basic Statistical Visualizations\n",
    "\n",
    "Create fundamental visualizations to understand the distribution and characteristics of variant effect scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistical visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('ğŸ§¬ VEP Analysis: Statistical Overview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Effect Score Distribution\n",
    "axes[0, 0].hist(vep_results['cosine_score'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].axvline(vep_results['cosine_score'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {vep_results[\"cosine_score\"].mean():.3f}')\n",
    "axes[0, 0].axvline(0.15, color='orange', linestyle='--', label='Threshold: 0.15')\n",
    "axes[0, 0].set_xlabel('Cosine Distance Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('ğŸ“Š Effect Score Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Functional vs Neutral Scores\n",
    "functional_scores = vep_results[vep_results['predicted_functional']]['cosine_score']\n",
    "neutral_scores = vep_results[~vep_results['predicted_functional']]['cosine_score']\n",
    "\n",
    "axes[0, 1].hist([functional_scores, neutral_scores], bins=20, alpha=0.7,\n",
    "                label=['Functional', 'Neutral'], color=['coral', 'lightblue'])\n",
    "axes[0, 1].set_xlabel('Cosine Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('âš¡ Functional vs Neutral Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Variant Type Effect Scores\n",
    "variant_type_scores = [vep_results[vep_results['variant_type'] == vt]['cosine_score'].values \n",
    "                      for vt in vep_results['variant_type'].unique()]\n",
    "axes[0, 2].boxplot(variant_type_scores, labels=vep_results['variant_type'].unique())\n",
    "axes[0, 2].set_xlabel('Variant Type')\n",
    "axes[0, 2].set_ylabel('Cosine Score')\n",
    "axes[0, 2].set_title('ğŸ”„ Effect Scores by Variant Type')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Chromosome Distribution\n",
    "chrom_counts = vep_results['chromosome'].value_counts().head(10)\n",
    "axes[1, 0].bar(range(len(chrom_counts)), chrom_counts.values, color='lightgreen')\n",
    "axes[1, 0].set_xticks(range(len(chrom_counts)))\n",
    "axes[1, 0].set_xticklabels(chrom_counts.index, rotation=45)\n",
    "axes[1, 0].set_xlabel('Chromosome')\n",
    "axes[1, 0].set_ylabel('Variant Count')\n",
    "axes[1, 0].set_title('ğŸ—ºï¸ Variant Distribution by Chromosome')\n",
    "\n",
    "# 5. Score Correlation Matrix\n",
    "score_cols = ['cosine_score', 'euclidean_score', 'manhattan_score', 'confidence']\n",
    "corr_matrix = vep_results[score_cols].corr()\n",
    "im = axes[1, 1].imshow(corr_matrix, cmap='coolwarm', aspect='auto')\n",
    "axes[1, 1].set_xticks(range(len(score_cols)))\n",
    "axes[1, 1].set_yticks(range(len(score_cols)))\n",
    "axes[1, 1].set_xticklabels([col.replace('_', ' ').title() for col in score_cols])\n",
    "axes[1, 1].set_yticklabels([col.replace('_', ' ').title() for col in score_cols])\n",
    "axes[1, 1].set_title('ğŸ”— Score Correlations')\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(score_cols)):\n",
    "    for j in range(len(score_cols)):\n",
    "        axes[1, 1].text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                        ha='center', va='center', color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black')\n",
    "\n",
    "# 6. Population Frequency vs Effect Score\n",
    "scatter = axes[1, 2].scatter(vep_results['population_frequency'], vep_results['cosine_score'],\n",
    "                            c=vep_results['predicted_functional'], cmap='RdYlBu_r', alpha=0.6)\n",
    "axes[1, 2].set_xlabel('Population Frequency')\n",
    "axes[1, 2].set_ylabel('Cosine Score')\n",
    "axes[1, 2].set_title('ğŸ“ˆ Effect Score vs Population Frequency')\n",
    "axes[1, 2].set_xscale('log')\n",
    "plt.colorbar(scatter, ax=axes[1, 2], label='Functional Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Basic statistical visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ed15b",
   "metadata": {},
   "source": [
    "## 3. Advanced Interactive Visualizations\n",
    "\n",
    "Create interactive plots using Plotly for better data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive visualizations using Plotly\n",
    "print(\"ğŸš€ Creating interactive visualizations...\")\n",
    "\n",
    "# 1. Interactive Scatter Plot with Multiple Dimensions\n",
    "fig_scatter = px.scatter(\n",
    "    vep_results, \n",
    "    x='cosine_score', \n",
    "    y='euclidean_score',\n",
    "    color='variant_type',\n",
    "    size='confidence',\n",
    "    hover_data=['variant_id', 'chromosome', 'position', 'predicted_functional'],\n",
    "    title='ğŸ§¬ Interactive VEP Score Analysis',\n",
    "    labels={\n",
    "        'cosine_score': 'Cosine Distance Score',\n",
    "        'euclidean_score': 'Euclidean Distance Score',\n",
    "        'variant_type': 'Variant Type'\n",
    "    }\n",
    ")\n",
    "fig_scatter.add_hline(y=vep_results['euclidean_score'].mean(), line_dash=\"dash\", \n",
    "                     annotation_text=\"Mean Euclidean Score\")\n",
    "fig_scatter.add_vline(x=0.15, line_dash=\"dash\", line_color=\"red\",\n",
    "                     annotation_text=\"Functional Threshold\")\n",
    "fig_scatter.show()\n",
    "\n",
    "# 2. Interactive Genomic Distribution\n",
    "fig_genome = px.scatter(\n",
    "    vep_results,\n",
    "    x='position',\n",
    "    y='cosine_score',\n",
    "    color='predicted_functional',\n",
    "    facet_col='chromosome',\n",
    "    facet_col_wrap=6,\n",
    "    title='ğŸ—ºï¸ Genomic Distribution of Variant Effects',\n",
    "    labels={\n",
    "        'position': 'Genomic Position',\n",
    "        'cosine_score': 'Effect Score',\n",
    "        'predicted_functional': 'Functional Prediction'\n",
    "    },\n",
    "    height=800\n",
    ")\n",
    "fig_genome.show()\n",
    "\n",
    "# 3. Interactive Box Plot by Genomic Region\n",
    "fig_box = px.box(\n",
    "    vep_results,\n",
    "    x='genomic_region',\n",
    "    y='cosine_score',\n",
    "    color='variant_type',\n",
    "    title='ğŸ“Š Effect Scores by Genomic Region and Variant Type',\n",
    "    labels={\n",
    "        'genomic_region': 'Genomic Region',\n",
    "        'cosine_score': 'Effect Score',\n",
    "        'variant_type': 'Variant Type'\n",
    "    }\n",
    ")\n",
    "fig_box.show()\n",
    "\n",
    "print(\"âœ… Interactive visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d514b4",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis and ROC Curves\n",
    "\n",
    "Analyze prediction performance using ROC curves and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction performance\n",
    "print(\"ğŸ“ˆ Analyzing prediction performance...\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(vep_results['true_functional'], vep_results['cosine_score'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create performance analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ¯ VEP Prediction Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. ROC Curve\n",
    "axes[0, 0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "axes[0, 0].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random Classifier')\n",
    "axes[0, 0].set_xlabel('False Positive Rate')\n",
    "axes[0, 0].set_ylabel('True Positive Rate')\n",
    "axes[0, 0].set_title('ğŸ“Š ROC Curve Analysis')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Precision-Recall Analysis\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(vep_results['true_functional'], vep_results['cosine_score'])\n",
    "avg_precision = average_precision_score(vep_results['true_functional'], vep_results['cosine_score'])\n",
    "\n",
    "axes[0, 1].plot(recall, precision, color='red', lw=2, label=f'PR Curve (AP = {avg_precision:.3f})')\n",
    "axes[0, 1].set_xlabel('Recall')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('ğŸ“ˆ Precision-Recall Curve')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "cm = confusion_matrix(vep_results['true_functional'], vep_results['predicted_functional'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['Predicted Neutral', 'Predicted Functional'],\n",
    "            yticklabels=['True Neutral', 'True Functional'])\n",
    "axes[1, 0].set_title('ğŸ¯ Confusion Matrix')\n",
    "axes[1, 0].set_ylabel('True Label')\n",
    "axes[1, 0].set_xlabel('Predicted Label')\n",
    "\n",
    "# 4. Score Distribution by True Label\n",
    "true_func_scores = vep_results[vep_results['true_functional']]['cosine_score']\n",
    "true_neut_scores = vep_results[~vep_results['true_functional']]['cosine_score']\n",
    "\n",
    "axes[1, 1].hist([true_func_scores, true_neut_scores], bins=20, alpha=0.7,\n",
    "                label=['True Functional', 'True Neutral'], color=['orange', 'cyan'])\n",
    "axes[1, 1].axvline(0.15, color='red', linestyle='--', label='Classification Threshold')\n",
    "axes[1, 1].set_xlabel('Cosine Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('ğŸ“Š Score Distribution by True Label')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nğŸ“‹ Classification Report:\")\n",
    "print(classification_report(vep_results['true_functional'], vep_results['predicted_functional'],\n",
    "                          target_names=['Neutral', 'Functional']))\n",
    "\n",
    "# Performance metrics summary\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print(f\"\\nğŸ¯ Performance Metrics Summary:\")\n",
    "print(f\"  ğŸ“Š ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"  ğŸ“ˆ Average Precision: {avg_precision:.3f}\")\n",
    "print(f\"  ğŸ¯ Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "print(f\"  ğŸ›¡ï¸ Specificity: {specificity:.3f}\")\n",
    "print(f\"  âœ… Positive Predictive Value: {ppv:.3f}\")\n",
    "print(f\"  âŒ Negative Predictive Value: {npv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7beaf18",
   "metadata": {},
   "source": [
    "## 5. Publication-Ready Visualizations\n",
    "\n",
    "Create high-quality, publication-ready plots with proper styling and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-ready visualizations\n",
    "print(\"ğŸ“„ Creating publication-ready visualizations...\")\n",
    "\n",
    "# Set publication style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 16\n",
    "})\n",
    "\n",
    "# Publication Figure 1: Comprehensive Effect Score Analysis\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Main distribution plot\n",
    "ax_main = fig.add_subplot(gs[0, :2])\n",
    "n, bins, patches = ax_main.hist(vep_results['cosine_score'], bins=40, alpha=0.7, \n",
    "                               color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "ax_main.axvline(vep_results['cosine_score'].mean(), color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Mean: {vep_results[\"cosine_score\"].mean():.3f}')\n",
    "ax_main.axvline(0.15, color='orange', linestyle='--', linewidth=2, \n",
    "               label='Functional Threshold: 0.15')\n",
    "ax_main.set_xlabel('Variant Effect Score (Cosine Distance)')\n",
    "ax_main.set_ylabel('Number of Variants')\n",
    "ax_main.set_title('A. Distribution of Variant Effect Scores', fontweight='bold')\n",
    "ax_main.legend()\n",
    "ax_main.grid(True, alpha=0.3)\n",
    "\n",
    "# Functional vs Neutral comparison\n",
    "ax_comp = fig.add_subplot(gs[0, 2:])\n",
    "parts = ax_comp.violinplot([functional_scores, neutral_scores], positions=[1, 2], \n",
    "                          showmeans=True, showmedians=True)\n",
    "ax_comp.set_xticks([1, 2])\n",
    "ax_comp.set_xticklabels(['Functional\\n(n={})'.format(len(functional_scores)), \n",
    "                        'Neutral\\n(n={})'.format(len(neutral_scores))])\n",
    "ax_comp.set_ylabel('Effect Score')\n",
    "ax_comp.set_title('B. Functional vs Neutral Variants', fontweight='bold')\n",
    "ax_comp.grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "ax_roc = fig.add_subplot(gs[1, :2])\n",
    "ax_roc.plot(fpr, tpr, color='blue', lw=3, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "ax_roc.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', alpha=0.7)\n",
    "ax_roc.set_xlabel('False Positive Rate')\n",
    "ax_roc.set_ylabel('True Positive Rate')\n",
    "ax_roc.set_title('C. Receiver Operating Characteristic', fontweight='bold')\n",
    "ax_roc.legend()\n",
    "ax_roc.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax_pr = fig.add_subplot(gs[1, 2:])\n",
    "ax_pr.plot(recall, precision, color='red', lw=3, label=f'PR Curve (AP = {avg_precision:.3f})')\n",
    "ax_pr.set_xlabel('Recall (Sensitivity)')\n",
    "ax_pr.set_ylabel('Precision')\n",
    "ax_pr.set_title('D. Precision-Recall Curve', fontweight='bold')\n",
    "ax_pr.legend()\n",
    "ax_pr.grid(True, alpha=0.3)\n",
    "\n",
    "# Variant type analysis\n",
    "ax_type = fig.add_subplot(gs[2, :2])\n",
    "type_summary = vep_results.groupby('variant_type').agg({\n",
    "    'cosine_score': ['mean', 'std'],\n",
    "    'predicted_functional': 'sum'\n",
    "}).round(3)\n",
    "type_summary.columns = ['Mean_Score', 'Std_Score', 'Functional_Count']\n",
    "type_summary = type_summary.reset_index()\n",
    "\n",
    "x_pos = np.arange(len(type_summary))\n",
    "ax_type.bar(x_pos, type_summary['Mean_Score'], yerr=type_summary['Std_Score'],\n",
    "           capsize=5, color='lightcoral', alpha=0.8, edgecolor='black')\n",
    "ax_type.set_xticks(x_pos)\n",
    "ax_type.set_xticklabels(type_summary['variant_type'], rotation=45, ha='right')\n",
    "ax_type.set_ylabel('Mean Effect Score')\n",
    "ax_type.set_title('E. Effect Scores by Variant Type', fontweight='bold')\n",
    "ax_type.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance metrics summary\n",
    "ax_metrics = fig.add_subplot(gs[2, 2:])\n",
    "metrics_data = {\n",
    "    'Metric': ['Sensitivity', 'Specificity', 'PPV', 'NPV', 'ROC AUC'],\n",
    "    'Value': [sensitivity, specificity, ppv, npv, roc_auc]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "bars = ax_metrics.bar(metrics_df['Metric'], metrics_df['Value'], \n",
    "                     color=['skyblue', 'lightgreen', 'gold', 'plum', 'salmon'],\n",
    "                     edgecolor='black', alpha=0.8)\n",
    "ax_metrics.set_ylabel('Performance Score')\n",
    "ax_metrics.set_title('F. Performance Metrics Summary', fontweight='bold')\n",
    "ax_metrics.set_ylim(0, 1)\n",
    "ax_metrics.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_df['Value']):\n",
    "    height = bar.get_height()\n",
    "    ax_metrics.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Variant Effect Prediction Analysis Results', fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Publication-ready visualization created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b5d08",
   "metadata": {},
   "source": [
    "## 6. Export Functions and Formats\n",
    "\n",
    "Implement comprehensive export functionality for different output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b40fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functions for different formats\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def export_vep_results(results_df: pd.DataFrame, output_dir: str = \"vep_exports\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Export VEP results in multiple formats.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with VEP analysis results\n",
    "        output_dir: Directory to save exported files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of exported file paths\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    exported_files = {}\n",
    "    \n",
    "    # 1. CSV Export (basic)\n",
    "    csv_file = os.path.join(output_dir, f\"vep_results_{timestamp}.csv\")\n",
    "    results_df.to_csv(csv_file, index=False)\n",
    "    exported_files['csv'] = csv_file\n",
    "    \n",
    "    # 2. Excel Export (multiple sheets)\n",
    "    excel_file = os.path.join(output_dir, f\"vep_analysis_{timestamp}.xlsx\")\n",
    "    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "        # All results\n",
    "        results_df.to_excel(writer, sheet_name='All_Variants', index=False)\n",
    "        \n",
    "        # Functional variants only\n",
    "        functional_variants = results_df[results_df['predicted_functional']]\n",
    "        functional_variants.to_excel(writer, sheet_name='Functional_Variants', index=False)\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary_stats = results_df.groupby('variant_type').agg({\n",
    "            'cosine_score': ['count', 'mean', 'std', 'min', 'max'],\n",
    "            'predicted_functional': 'sum'\n",
    "        }).round(4)\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary_Statistics')\n",
    "        \n",
    "        # Performance metrics\n",
    "        perf_metrics = pd.DataFrame({\n",
    "            'Metric': ['True Positives', 'False Positives', 'True Negatives', 'False Negatives',\n",
    "                      'Sensitivity', 'Specificity', 'PPV', 'NPV', 'ROC AUC'],\n",
    "            'Value': [tp, fp, tn, fn, sensitivity, specificity, ppv, npv, roc_auc]\n",
    "        })\n",
    "        perf_metrics.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "    \n",
    "    exported_files['excel'] = excel_file\n",
    "    \n",
    "    # 3. JSON Export (for web applications)\n",
    "    json_file = os.path.join(output_dir, f\"vep_results_{timestamp}.json\")\n",
    "    # Convert to records format for JSON\n",
    "    json_data = {\n",
    "        'analysis_info': {\n",
    "            'timestamp': timestamp,\n",
    "            'total_variants': len(results_df),\n",
    "            'functional_variants': results_df['predicted_functional'].sum(),\n",
    "            'mean_effect_score': float(results_df['cosine_score'].mean()),\n",
    "            'performance_metrics': {\n",
    "                'roc_auc': float(roc_auc),\n",
    "                'sensitivity': float(sensitivity),\n",
    "                'specificity': float(specificity)\n",
    "            }\n",
    "        },\n",
    "        'variants': results_df.to_dict('records')\n",
    "    }\n",
    "    \n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    exported_files['json'] = json_file\n",
    "    \n",
    "    # 4. BED format for genomic tools\n",
    "    bed_file = os.path.join(output_dir, f\"functional_variants_{timestamp}.bed\")\n",
    "    bed_data = functional_variants[['chromosome', 'position', 'position', 'variant_id', 'cosine_score']].copy()\n",
    "    bed_data['end_position'] = bed_data['position'] + 1  # BED format uses 0-based coordinates\n",
    "    bed_data = bed_data[['chromosome', 'position', 'end_position', 'variant_id', 'cosine_score']]\n",
    "    bed_data.to_csv(bed_file, sep='\\t', index=False, header=False)\n",
    "    exported_files['bed'] = bed_file\n",
    "    \n",
    "    # 5. VCF-like format for compatibility\n",
    "    vcf_file = os.path.join(output_dir, f\"vep_annotations_{timestamp}.txt\")\n",
    "    vcf_data = results_df[['chromosome', 'position', 'variant_id', 'ref_allele', 'alt_allele', \n",
    "                          'cosine_score', 'predicted_functional', 'confidence']].copy()\n",
    "    vcf_data.to_csv(vcf_file, sep='\\t', index=False)\n",
    "    exported_files['vcf_like'] = vcf_file\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "def create_analysis_report(results_df: pd.DataFrame, output_dir: str = \"vep_exports\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive analysis report.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with VEP analysis results\n",
    "        output_dir: Directory to save report\n",
    "        \n",
    "    Returns:\n",
    "        Path to generated report\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    report_file = os.path.join(output_dir, f\"vep_analysis_report_{timestamp}.txt\")\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(\"VARIANT EFFECT PREDICTION ANALYSIS REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        # Dataset Summary\n",
    "        f.write(\"DATASET SUMMARY\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Total variants analyzed: {len(results_df)}\\n\")\n",
    "        f.write(f\"Predicted functional variants: {results_df['predicted_functional'].sum()}\\n\")\n",
    "        f.write(f\"Predicted neutral variants: {(~results_df['predicted_functional']).sum()}\\n\")\n",
    "        f.write(f\"Functional rate: {results_df['predicted_functional'].mean():.1%}\\n\\n\")\n",
    "        \n",
    "        # Effect Score Statistics\n",
    "        f.write(\"EFFECT SCORE STATISTICS\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\n\")\n",
    "        f.write(f\"Mean cosine score: {results_df['cosine_score'].mean():.4f}\\n\")\n",
    "        f.write(f\"Median cosine score: {results_df['cosine_score'].median():.4f}\\n\")\n",
    "        f.write(f\"Standard deviation: {results_df['cosine_score'].std():.4f}\\n\")\n",
    "        f.write(f\"Min score: {results_df['cosine_score'].min():.4f}\\n\")\n",
    "        f.write(f\"Max score: {results_df['cosine_score'].max():.4f}\\n\\n\")\n",
    "        \n",
    "        # Variant Type Analysis\n",
    "        f.write(\"VARIANT TYPE ANALYSIS\\n\")\n",
    "        f.write(\"-\" * 22 + \"\\n\")\n",
    "        type_stats = results_df.groupby('variant_type').agg({\n",
    "            'cosine_score': ['count', 'mean', 'std'],\n",
    "            'predicted_functional': 'sum'\n",
    "        }).round(4)\n",
    "        f.write(type_stats.to_string() + \"\\n\\n\")\n",
    "        \n",
    "        # Performance Metrics\n",
    "        f.write(\"PERFORMANCE METRICS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"ROC AUC: {roc_auc:.3f}\\n\")\n",
    "        f.write(f\"Sensitivity (Recall): {sensitivity:.3f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.3f}\\n\")\n",
    "        f.write(f\"Positive Predictive Value: {ppv:.3f}\\n\")\n",
    "        f.write(f\"Negative Predictive Value: {npv:.3f}\\n\\n\")\n",
    "        \n",
    "        # Top Functional Variants\n",
    "        f.write(\"TOP 10 FUNCTIONAL VARIANTS\\n\")\n",
    "        f.write(\"-\" * 27 + \"\\n\")\n",
    "        top_functional = results_df[results_df['predicted_functional']].nlargest(10, 'cosine_score')\n",
    "        for i, (_, variant) in enumerate(top_functional.iterrows(), 1):\n",
    "            f.write(f\"{i:2d}. {variant['variant_id']} ({variant['chromosome']}:{variant['position']}) - \")\n",
    "            f.write(f\"Score: {variant['cosine_score']:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "        f.write(\"End of Report\\n\")\n",
    "    \n",
    "    return report_file\n",
    "\n",
    "# Export results in multiple formats\n",
    "print(\"ğŸ“¤ Exporting VEP results in multiple formats...\")\n",
    "exported_files = export_vep_results(vep_results)\n",
    "\n",
    "print(\"âœ… Export completed!\")\n",
    "print(\"ğŸ“ Exported files:\")\n",
    "for format_type, file_path in exported_files.items():\n",
    "    print(f\"  ğŸ“„ {format_type.upper()}: {file_path}\")\n",
    "\n",
    "# Generate analysis report\n",
    "report_file = create_analysis_report(vep_results)\n",
    "print(f\"  ğŸ“‹ Report: {report_file}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ All files exported to: vep_exports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12be881",
   "metadata": {},
   "source": [
    "## 7. Custom Visualization Functions\n",
    "\n",
    "Create reusable functions for generating specific types of VEP visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52511acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vep_dashboard(results_df: pd.DataFrame, save_path: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Create a comprehensive VEP analysis dashboard.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with VEP results\n",
    "        save_path: Optional path to save the dashboard image\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # Color palette\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "    \n",
    "    # 1. Score distribution\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.hist(results_df['cosine_score'], bins=30, alpha=0.7, color=colors[0], edgecolor='black')\n",
    "    ax1.axvline(0.15, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "    ax1.set_title('Effect Score Distribution', fontweight='bold')\n",
    "    ax1.set_xlabel('Cosine Score')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Functional prediction pie chart\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    func_counts = results_df['predicted_functional'].value_counts()\n",
    "    ax2.pie(func_counts.values, labels=['Neutral', 'Functional'], colors=[colors[1], colors[2]], \n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('Functional Predictions', fontweight='bold')\n",
    "    \n",
    "    # 3. Variant type distribution\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    type_counts = results_df['variant_type'].value_counts()\n",
    "    ax3.bar(range(len(type_counts)), type_counts.values, color=colors[:len(type_counts)])\n",
    "    ax3.set_xticks(range(len(type_counts)))\n",
    "    ax3.set_xticklabels(type_counts.index, rotation=45, ha='right')\n",
    "    ax3.set_title('Variant Types', fontweight='bold')\n",
    "    ax3.set_ylabel('Count')\n",
    "    \n",
    "    # 4. ROC curve\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.plot(fpr, tpr, color=colors[3], lw=3, label=f'AUC = {roc_auc:.3f}')\n",
    "    ax4.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    ax4.set_title('ROC Curve', fontweight='bold')\n",
    "    ax4.set_xlabel('False Positive Rate')\n",
    "    ax4.set_ylabel('True Positive Rate')\n",
    "    ax4.legend()\n",
    "    \n",
    "    # 5. Score by genomic region\n",
    "    ax5 = fig.add_subplot(gs[1, :2])\n",
    "    region_data = [results_df[results_df['genomic_region'] == region]['cosine_score'].values \n",
    "                   for region in results_df['genomic_region'].unique()]\n",
    "    bp = ax5.boxplot(region_data, labels=results_df['genomic_region'].unique(), patch_artist=True)\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    ax5.set_title('Effect Scores by Genomic Region', fontweight='bold')\n",
    "    ax5.set_ylabel('Cosine Score')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Chromosome distribution\n",
    "    ax6 = fig.add_subplot(gs[1, 2:])\n",
    "    chrom_func = results_df.groupby('chromosome')['predicted_functional'].sum().head(15)\n",
    "    chrom_total = results_df['chromosome'].value_counts().head(15)\n",
    "    \n",
    "    x_pos = np.arange(len(chrom_func))\n",
    "    width = 0.35\n",
    "    ax6.bar(x_pos - width/2, chrom_total[chrom_func.index], width, \n",
    "           label='Total', color=colors[0], alpha=0.7)\n",
    "    ax6.bar(x_pos + width/2, chrom_func.values, width, \n",
    "           label='Functional', color=colors[2], alpha=0.7)\n",
    "    ax6.set_xticks(x_pos)\n",
    "    ax6.set_xticklabels(chrom_func.index, rotation=45)\n",
    "    ax6.set_title('Variants by Chromosome', fontweight='bold')\n",
    "    ax6.set_ylabel('Count')\n",
    "    ax6.legend()\n",
    "    \n",
    "    # 7. Performance metrics radar\n",
    "    ax7 = fig.add_subplot(gs[2, 0], projection='polar')\n",
    "    metrics = ['Sensitivity', 'Specificity', 'PPV', 'NPV']\n",
    "    values = [sensitivity, specificity, ppv, npv]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
    "    values += values[:1]  # Complete the circle\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax7.plot(angles, values, 'o-', linewidth=2, color=colors[3])\n",
    "    ax7.fill(angles, values, alpha=0.25, color=colors[3])\n",
    "    ax7.set_xticks(angles[:-1])\n",
    "    ax7.set_xticklabels(metrics)\n",
    "    ax7.set_ylim(0, 1)\n",
    "    ax7.set_title('Performance Metrics', fontweight='bold', pad=20)\n",
    "    \n",
    "    # 8. Score correlation heatmap\n",
    "    ax8 = fig.add_subplot(gs[2, 1:3])\n",
    "    score_cols = ['cosine_score', 'euclidean_score', 'manhattan_score', 'confidence']\n",
    "    corr_matrix = results_df[score_cols].corr()\n",
    "    im = ax8.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    ax8.set_xticks(range(len(score_cols)))\n",
    "    ax8.set_yticks(range(len(score_cols)))\n",
    "    ax8.set_xticklabels([col.replace('_', ' ').title() for col in score_cols], rotation=45)\n",
    "    ax8.set_yticklabels([col.replace('_', ' ').title() for col in score_cols])\n",
    "    ax8.set_title('Score Correlations', fontweight='bold')\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i in range(len(score_cols)):\n",
    "        for j in range(len(score_cols)):\n",
    "            ax8.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                    ha='center', va='center', \n",
    "                    color='white' if abs(corr_matrix.iloc[i, j]) > 0.6 else 'black')\n",
    "    \n",
    "    # 9. Top variants table\n",
    "    ax9 = fig.add_subplot(gs[2, 3])\n",
    "    ax9.axis('tight')\n",
    "    ax9.axis('off')\n",
    "    top_variants = results_df.nlargest(10, 'cosine_score')[['variant_id', 'cosine_score', 'variant_type']]\n",
    "    table_data = []\n",
    "    for _, row in top_variants.iterrows():\n",
    "        table_data.append([row['variant_id'][:12], f\"{row['cosine_score']:.3f}\", row['variant_type'][:8]])\n",
    "    \n",
    "    table = ax9.table(cellText=table_data, \n",
    "                     colLabels=['Variant ID', 'Score', 'Type'],\n",
    "                     cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "    ax9.set_title('Top 10 Variants', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('VEP Analysis Dashboard', fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š Dashboard saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_variant_manhattan_plot(results_df: pd.DataFrame, save_path: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Create a Manhattan plot showing variant effects across chromosomes.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with VEP results\n",
    "        save_path: Optional path to save the plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    # Prepare data for Manhattan plot\n",
    "    chromosomes = sorted(results_df['chromosome'].unique(), key=lambda x: (len(x), x))\n",
    "    colors = ['#1f77b4', '#ff7f0e'] * (len(chromosomes) // 2 + 1)\n",
    "    \n",
    "    x_offset = 0\n",
    "    x_ticks = []\n",
    "    x_labels = []\n",
    "    \n",
    "    for i, chrom in enumerate(chromosomes):\n",
    "        chrom_data = results_df[results_df['chromosome'] == chrom].copy()\n",
    "        chrom_data = chrom_data.sort_values('position')\n",
    "        \n",
    "        # Normalize positions for plotting\n",
    "        if len(chrom_data) > 0:\n",
    "            x_positions = x_offset + np.arange(len(chrom_data))\n",
    "            \n",
    "            # Plot points\n",
    "            scatter = ax.scatter(x_positions, chrom_data['cosine_score'], \n",
    "                               c=chrom_data['predicted_functional'], \n",
    "                               cmap='RdYlBu_r', alpha=0.7, s=30)\n",
    "            \n",
    "            # Track x-axis labels\n",
    "            x_ticks.append(x_offset + len(chrom_data) / 2)\n",
    "            x_labels.append(chrom.replace('chr', ''))\n",
    "            \n",
    "            x_offset += len(chrom_data) + 1000  # Add spacing between chromosomes\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.axhline(y=0.15, color='red', linestyle='--', alpha=0.8, label='Functional Threshold')\n",
    "    ax.set_xlabel('Chromosome', fontsize=12)\n",
    "    ax.set_ylabel('Variant Effect Score', fontsize=12)\n",
    "    ax.set_title('Manhattan Plot: Variant Effects Across Genome', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label('Functional Prediction', rotation=270, labelpad=15)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ—ºï¸ Manhattan plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Create dashboard and Manhattan plot\n",
    "print(\"ğŸ¨ Creating comprehensive VEP dashboard...\")\n",
    "create_vep_dashboard(vep_results, \"vep_exports/vep_dashboard.png\")\n",
    "\n",
    "print(\"ğŸ—ºï¸ Creating Manhattan plot...\")\n",
    "create_variant_manhattan_plot(vep_results, \"vep_exports/manhattan_plot.png\")\n",
    "\n",
    "print(\"âœ… Custom visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1546134",
   "metadata": {},
   "source": [
    "## 8. Summary and Best Practices\n",
    "\n",
    "### ğŸ¯ Key Visualization Principles for VEP Analysis\n",
    "\n",
    "1. **ğŸ“Š Comprehensive Overview**\n",
    "   - Always start with distribution plots to understand your data\n",
    "   - Include both statistical and biological perspectives\n",
    "   - Show both raw scores and interpreted predictions\n",
    "\n",
    "2. **ğŸ” Interactive Exploration**\n",
    "   - Use interactive plots for detailed data exploration\n",
    "   - Enable filtering and zooming for large datasets\n",
    "   - Provide hover information for context\n",
    "\n",
    "3. **ğŸ“ˆ Performance Visualization**\n",
    "   - ROC and PR curves are essential for binary classification\n",
    "   - Confusion matrices provide clear performance overview\n",
    "   - Include confidence intervals when possible\n",
    "\n",
    "4. **ğŸ§¬ Biological Context**\n",
    "   - Manhattan plots show genomic distribution\n",
    "   - Variant type analysis reveals biological patterns\n",
    "   - Genomic region analysis provides functional insights\n",
    "\n",
    "5. **ğŸ“¤ Export Flexibility**\n",
    "   - Multiple formats serve different downstream needs\n",
    "   - Include metadata and analysis parameters\n",
    "   - Generate human-readable reports alongside raw data\n",
    "\n",
    "### ğŸ’¡ Best Practices Summary\n",
    "\n",
    "âœ… **Do:**\n",
    "- Create multiple complementary visualizations\n",
    "- Include statistical significance testing\n",
    "- Provide interactive versions for exploration\n",
    "- Export in multiple formats for different users\n",
    "- Include biological interpretation in reports\n",
    "\n",
    "âŒ **Avoid:**\n",
    "- Showing only one type of visualization\n",
    "- Ignoring statistical assumptions\n",
    "- Creating static-only visualizations for large datasets\n",
    "- Limiting export to single format\n",
    "- Providing results without biological context\n",
    "\n",
    "### ğŸš€ Next Steps\n",
    "\n",
    "1. **ğŸ”¬ Validation**: Compare predictions with experimental data\n",
    "2. **ğŸ“Š Scale**: Apply to larger genomic datasets\n",
    "3. **ğŸ§¬ Integration**: Combine with other genomic features\n",
    "4. **ğŸ¥ Clinical**: Implement in clinical variant interpretation pipelines\n",
    "5. **ğŸ“± Deployment**: Create web-based interactive dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and cleanup\n",
    "print(\"ğŸ‰ VEP Visualization and Export Tutorial Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ“Š Generated Visualizations:\")\n",
    "print(f\"  ğŸ“ˆ Statistical overview plots\")\n",
    "print(f\"  ğŸ” Interactive Plotly visualizations\")\n",
    "print(f\"  ğŸ“Š ROC and Precision-Recall curves\")\n",
    "print(f\"  ğŸ“„ Publication-ready figures\")\n",
    "print(f\"  ğŸ¨ Comprehensive dashboard\")\n",
    "print(f\"  ğŸ—ºï¸ Manhattan plot\")\n",
    "\n",
    "print(f\"\\nğŸ“¤ Export Formats Created:\")\n",
    "for format_type in exported_files.keys():\n",
    "    print(f\"  ğŸ“„ {format_type.upper()} format\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Output Directory: vep_exports/\")\n",
    "print(f\"  ğŸ“ Contains all plots, data exports, and reports\")\n",
    "\n",
    "print(f\"\\nğŸ“ Key Learning Outcomes:\")\n",
    "print(f\"  âœ… Comprehensive VEP result visualization\")\n",
    "print(f\"  âœ… Statistical analysis and performance evaluation\")\n",
    "print(f\"  âœ… Multiple export formats for different needs\")\n",
    "print(f\"  âœ… Publication-ready plot generation\")\n",
    "print(f\"  âœ… Interactive data exploration techniques\")\n",
    "\n",
    "print(f\"\\nğŸš€ Ready for:\")\n",
    "print(f\"  ğŸ”¬ Experimental validation\")\n",
    "print(f\"  ğŸ“Š Large-scale genomic analysis\")\n",
    "print(f\"  ğŸ¥ Clinical variant interpretation\")\n",
    "print(f\"  ğŸ“± Dashboard deployment\")\n",
    "\n",
    "print(f\"\\nâœ¨ Tutorial completed successfully! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
