{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693d1c00",
   "metadata": {},
   "source": [
    "# ü§ñ VEP Tutorial 2/4: Foundation Models for Variant Analysis\n",
    "\n",
    "Welcome to the second tutorial in our VEP series. This guide focuses on understanding and configuring **PlantRNA-FM** (Plant RNA Foundation Model) for extracting meaningful sequence embeddings in variant effect prediction.\n",
    "\n",
    "> üìö **Prerequisites**: \n",
    "> - Complete [Tutorial 1: Data Preparation](01_vep_data_preparation.ipynb)\n",
    "> - Understand the [Fundamental Concepts Tutorial](../00_fundamental_concepts.ipynb)\n",
    "\n",
    "Before loading models, let's understand *why* PlantRNA-FM and similar foundation models are powerful for variant effect prediction.\n",
    "\n",
    "## 1. Understanding Genomic Foundation Models üß†\n",
    "\n",
    "### 1.1 From Language Models to Genomic Models\n",
    "\n",
    "Just as **BERT** and **GPT** learned language patterns from massive text corpora, **PlantRNA-FM** learns biological patterns from vast plant RNA and genomic databases, representing a new generation of specialized foundation models for plant genomics.\n",
    "\n",
    "| Concept | Language Models | PlantRNA-FM |\n",
    "|---------|-----------------|---------------------------|\n",
    "| **Input** | Words, sentences | Plant RNA/DNA sequences |\n",
    "| **Training** | Books, Wikipedia | Plant genomic databases, transcriptomes |\n",
    "| **Learned patterns** | Grammar, syntax | Regulatory motifs, splicing signals, codon usage |\n",
    "| **Embeddings** | Semantic meaning | Biological function and structure |\n",
    "| **Applications** | Translation, QA | VEP, gene expression prediction, regulatory analysis |\n",
    "\n",
    "### 1.2 Why PlantRNA-FM for VEP?\n",
    "\n",
    "**Traditional approaches** (e.g., SIFT, PolyPhen) rely on:\n",
    "- ‚ùå Hand-crafted features (conservation scores, physicochemical properties)\n",
    "- ‚ùå Limited to known protein-coding regions\n",
    "- ‚ùå Require multiple sequence alignments\n",
    "\n",
    "**PlantRNA-FM and foundation model approaches** offer:\n",
    "- ‚úÖ **Learned representations**: Automatically discover plant-specific regulatory patterns\n",
    "- ‚úÖ **Contextual understanding**: Capture long-range dependencies in RNA structures\n",
    "- ‚úÖ **Transfer learning**: Apply knowledge from millions of plant sequences\n",
    "- ‚úÖ **Zero-shot capability**: Predict effects without variant-specific training\n",
    "- ‚úÖ **Plant-optimized**: Specialized for plant genomic features (e.g., alternative splicing, UTR structures)\n",
    "\n",
    "### 1.3 Embedding-Based VEP: The Core Idea\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Reference Sequence<br/>ATCG...] --> B[PlantRNA-FM]\n",
    "    C[Alternative Sequence<br/>AGCG...] --> B\n",
    "    B --> D[Embedding‚ÇÅ<br/>[768-dim vector]]\n",
    "    B --> E[Embedding‚ÇÇ<br/>[768-dim vector]]\n",
    "    D --> F[Compare<br/>Cosine Similarity]\n",
    "    E --> F\n",
    "    F --> G[Effect Score<br/>0.0 - 1.0]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style C fill:#ffe1e1\n",
    "    style D fill:#e1ffe1\n",
    "    style E fill:#ffe1f5\n",
    "    style G fill:#fff5e1\n",
    "```\n",
    "\n",
    "**Key insight**: If a variant significantly changes the embedding produced by PlantRNA-FM (low similarity), it likely has functional impact on the plant RNA or regulatory element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521c4fb",
   "metadata": {},
   "source": [
    "## 2. Choosing the Right Model üéØ\n",
    "\n",
    "### 2.1 Available Foundation Models\n",
    "\n",
    "| Model | Parameters | Context Length | Specialization | Publication |\n",
    "|-------|-----------|----------------|----------------|-------------|\n",
    "| **PlantRNA-FM** | **35M** | 1024 | Plant RNA & genomics | *Nature Machine Intelligence* |\n",
    "| **OmniGenome-52M** | 52M | 1024 | General genomics | - |\n",
    "| **OmniGenome-418M** | 418M | 4096 | Deep genomics | - |\n",
    "\n",
    "### 2.2 Model Selection Guidelines\n",
    "\n",
    "**For this tutorial, we use PlantRNA-FM** because:\n",
    "- üå± **Plant-specialized**: Trained on extensive plant RNA and genomic data\n",
    "- üéØ **Optimized for plant variants**: Better captures plant-specific regulatory elements\n",
    "- üöÄ **Efficient & powerful**: Only 35M parameters, published in *Nature Machine Intelligence*\n",
    "- üíæ **Low resource requirements**: Fast inference, small memory footprint (~140MB)\n",
    "- üìö **Well-validated**: Peer-reviewed and extensively tested on plant genomic tasks\n",
    "- ‚úÖ **Suitable for most plant VEP tasks**: Effective for gene expression, splicing, and regulatory variants\n",
    "\n",
    "**Consider alternatives when:**\n",
    "- **OmniGenome-52M**: Quick prototyping or non-plant organisms\n",
    "- **OmniGenome-418M**: Require maximum accuracy or very long sequences (>2000bp)\n",
    "- Working with mixed datasets (plant and non-plant sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6162b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üõ†Ô∏è Step-by-Step: Model Initialization\n",
    "\n",
    "### 3.1: Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from omnigenbench import (\n",
    "    OmniTokenizer,\n",
    "    OmniModelForSequenceClassification\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "print(f\"üíª CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ed4eb",
   "metadata": {},
   "source": [
    "### 3.2: Configuration\n",
    "\n",
    "Define model parameters with clear explanations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for VEP model setup with PlantRNA-FM\"\"\"\n",
    "    # Model selection - Using PlantRNA-FM for plant variant analysis\n",
    "    model_name: str = \"yangheng/PlantRNA-FM\"  # Plant RNA Foundation Model\n",
    "    \n",
    "    # Task settings\n",
    "    num_labels: int = 2  # Binary classification (benign/pathogenic)\n",
    "    \n",
    "    # Embedding extraction\n",
    "    output_hidden_states: bool = True  # Required for embedding extraction\n",
    "    output_attentions: bool = False  # Set True to analyze attention patterns\n",
    "    \n",
    "    # Device management\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "config = ModelConfig()\n",
    "print(\"üìã Model Configuration:\")\n",
    "print(f\"   Model: {config.model_name}\")\n",
    "print(f\"   Device: {config.device}\")\n",
    "print(f\"   Output embeddings: {config.output_hidden_states}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e45c5d",
   "metadata": {},
   "source": [
    "### 3.3: Load PlantRNA-FM Model and Tokenizer\n",
    "\n",
    "**What happens during PlantRNA-FM loading:**\n",
    "1. üîΩ Download pre-trained PlantRNA-FM weights from Hugging Face (if not cached)\n",
    "2. üèóÔ∏è Initialize PlantRNA-FM architecture\n",
    "3. ‚öñÔ∏è Load plant-specific learned parameters\n",
    "4. üî§ Configure RNA/DNA tokenizer\n",
    "5. üéØ Set up for evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "print(\"üî§ Loading tokenizer...\")\n",
    "tokenizer = OmniTokenizer.from_pretrained(\n",
    "    config.model_name, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(f\"   Vocabulary size: {len(tokenizer)}\")\n",
    "print(f\"   Special tokens: {tokenizer.all_special_tokens}\")\n",
    "print(\"‚úÖ Tokenizer loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained PlantRNA-FM model\n",
    "print(\"\\nü§ñ Loading PlantRNA-FM...\")\n",
    "model = OmniModelForSequenceClassification.from_pretrained(\n",
    "    config.model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    num_labels=config.num_labels,\n",
    "    trust_remote_code=True,\n",
    "    output_hidden_states=config.output_hidden_states,\n",
    "    output_attentions=config.output_attentions\n",
    ")\n",
    "\n",
    "# Move to appropriate device\n",
    "model = model.to(config.device)\n",
    "\n",
    "# Set to evaluation mode (disables dropout, batch norm)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ PlantRNA-FM loaded successfully!\")\n",
    "print(f\"   Device: {next(model.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f30079",
   "metadata": {},
   "source": [
    "## 4. Model Verification & Analysis üîç\n",
    "\n",
    "Let's examine the model architecture and verify it's ready for VEP:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model statistics\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"üìä Model Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total parameters: {num_params:,} ({num_params/1e6:.1f}M)\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{num_params * 4 / 1024**2:.1f} MB\")\n",
    "\n",
    "# Model architecture overview\n",
    "print(\"\\nüèóÔ∏è Model Architecture:\")\n",
    "print(\"=\" * 50)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65f972",
   "metadata": {},
   "source": [
    "### 4.1: Understanding Model Outputs\n",
    "\n",
    "For VEP, we need to understand what the model produces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample sequence\n",
    "print(\"üß™ Testing model outputs...\")\n",
    "test_sequence = \"ATCGATCGATCG\" * 10  # 120bp test sequence\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(\n",
    "    test_sequence, \n",
    "    return_tensors=\"pt\", \n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "inputs = {k: v.to(config.device) for k, v in inputs.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "print(\"\\nüì§ Model Outputs:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Logits shape: {outputs.logits.shape}\")\n",
    "print(f\"  ‚Üí (batch_size, num_labels)\")\n",
    "print(f\"\\nHidden states: {len(outputs.hidden_states)} layers\")\n",
    "print(f\"  ‚Üí Layer 0 (embeddings): {outputs.hidden_states[0].shape}\")\n",
    "print(f\"  ‚Üí Layer -1 (final): {outputs.hidden_states[-1].shape}\")\n",
    "print(f\"  ‚Üí Shape: (batch_size, sequence_length, hidden_dim)\")\n",
    "\n",
    "# Extract embedding dimension\n",
    "embedding_dim = outputs.hidden_states[-1].shape[-1]\n",
    "print(f\"\\nüí° Embedding dimension: {embedding_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37ede6",
   "metadata": {},
   "source": [
    "### 4.2: Embedding Extraction for VEP\n",
    "\n",
    "For variant effect prediction, we extract embeddings from the final hidden layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(sequence, pooling='mean'):\n",
    "    \"\"\"\n",
    "    Extract sequence embedding from PlantRNA-FM.\n",
    "    \n",
    "    Args:\n",
    "        sequence: Plant DNA/RNA sequence string\n",
    "        pooling: 'mean', 'cls', or 'max' pooling strategy\n",
    "        \n",
    "    Returns:\n",
    "        Embedding vector (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        sequence,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    inputs = {k: v.to(config.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Extract hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get final layer hidden states\n",
    "    hidden_states = outputs.hidden_states[-1]  # (1, seq_len, hidden_dim)\n",
    "    \n",
    "    # Apply pooling\n",
    "    if pooling == 'mean':\n",
    "        # Average over sequence length\n",
    "        embedding = hidden_states.mean(dim=1).squeeze()\n",
    "    elif pooling == 'cls':\n",
    "        # Use CLS token (first position)\n",
    "        embedding = hidden_states[:, 0, :].squeeze()\n",
    "    elif pooling == 'max':\n",
    "        # Max pooling over sequence length\n",
    "        embedding = hidden_states.max(dim=1)[0].squeeze()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown pooling: {pooling}\")\n",
    "    \n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "# Test embedding extraction\n",
    "print(\"üß¨ Testing embedding extraction...\")\n",
    "ref_seq = \"ATCGATCGATCG\" * 10\n",
    "alt_seq = \"ATCGAGCGATCG\" * 10  # SNV: T‚ÜíG\n",
    "\n",
    "ref_emb = extract_embedding(ref_seq, pooling='mean')\n",
    "alt_emb = extract_embedding(alt_seq, pooling='mean')\n",
    "\n",
    "print(f\"\\n‚úÖ Embedding extraction successful!\")\n",
    "print(f\"   Reference embedding shape: {ref_emb.shape}\")\n",
    "print(f\"   Alternative embedding shape: {alt_emb.shape}\")\n",
    "print(f\"   Embedding L2 norm: {(ref_emb**2).sum()**0.5:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4847be8",
   "metadata": {},
   "source": [
    "### 4.3: Computing Variant Effect Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d276766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate similarity\n",
    "cosine_sim = 1 - cosine(ref_emb, alt_emb)\n",
    "effect_score = 1 - cosine_sim  # Higher score = larger effect\n",
    "\n",
    "print(\"üìä Variant Effect Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "print(f\"Effect score (1 - similarity): {effect_score:.4f}\")\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "if effect_score < 0.01:\n",
    "    print(\"   ‚Üí Likely benign (minimal embedding change)\")\n",
    "elif effect_score < 0.05:\n",
    "    print(\"   ‚Üí Possibly benign (small embedding change)\")\n",
    "else:\n",
    "    print(\"   ‚Üí Potentially functional (significant embedding change)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf11cd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary & Next Steps\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "In this tutorial, we:\n",
    "1. ‚úÖ **Understood PlantRNA-FM** - Learned how plant-specialized foundation models differ from traditional methods\n",
    "2. ‚úÖ **Loaded PlantRNA-FM** - Successfully initialized the plant RNA foundation model\n",
    "3. ‚úÖ **Verified model outputs** - Confirmed hidden states and embedding extraction\n",
    "4. ‚úÖ **Implemented embedding extraction** - Created reusable function for plant VEP\n",
    "5. ‚úÖ **Tested variant scoring** - Calculated effect scores from embeddings\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "üå± **PlantRNA-FM is plant-optimized**: Trained on extensive plant genomic data to capture plant-specific patterns\n",
    "\n",
    "üß† **Foundation models are powerful**: They learn from millions of sequences without manual feature engineering\n",
    "\n",
    "üìä **Embeddings capture biological meaning**: Similar sequences have similar embeddings\n",
    "\n",
    "üéØ **Effect = embedding distance**: Large changes suggest functional impact in plant regulatory elements\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "**Model Output Structure:**\n",
    "```python\n",
    "outputs.logits           # (batch, num_labels) - classification logits\n",
    "outputs.hidden_states    # List of (batch, seq_len, hidden_dim) per layer\n",
    "outputs.attentions       # Attention weights (if requested)\n",
    "```\n",
    "\n",
    "**Pooling Strategies:**\n",
    "- `mean`: Average over sequence ‚Üí robust to length variation\n",
    "- `cls`: Use CLS token ‚Üí follows BERT convention\n",
    "- `max`: Maximum values ‚Üí highlights salient features\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **[Tutorial 3: Embedding & Scoring](03_embedding_and_scoring.ipynb)** where we'll:\n",
    "- Process large variant datasets efficiently\n",
    "- Implement multiple scoring methods\n",
    "- Compare reference and alternative sequences\n",
    "- Analyze effect score distributions\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "# Load PlantRNA-FM and extract embeddings\n",
    "model = OmniModelForSequenceClassification.from_pretrained(\n",
    "    \"yangheng/PlantRNA-FM\", \n",
    "    tokenizer=tokenizer,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "outputs = model(**inputs)\n",
    "embedding = outputs.hidden_states[-1].mean(dim=1)\n",
    "```\n",
    "\n",
    "**Next Tutorial**: [03_embedding_and_scoring.ipynb](03_embedding_and_scoring.ipynb) üß¨\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
