{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed15a3631734b63",
   "metadata": {},
   "source": [
    "# Variant Effect Prediction with OmniGenBench\n",
    "\n",
    "This notebook demonstrates how to use various genomic foundation models for variant effect prediction. It processes genomic variants from a BED file, uses a reference genome, and predicts the functional effects of variants using deep learning models.\n",
    "\n",
    "**Dataset Description:**\n",
    "The dataset for this task consists of a BED file (`variant_effects_expression.bed`) containing human genetic variants associated with diseases, and the human reference genome (hg38). The BED file specifies the chromosome, start/end positions, reference allele, and alternative allele for each variant. The goal is to predict the functional impact of these variants by comparing the model's embeddings of the reference sequence versus the altered sequence. The data is sourced from the `yangheng/variant_effect_prediction` dataset on Hugging Face.\n",
    "\n",
    "**Estimated Runtime:**\n",
    "This notebook performs inference only (no training). The runtime depends on the model size and the number of variants processed. On a single NVIDIA RTX 4090 GPU, running the analysis on the full dataset (approximately 18k variant samples) takes about **15-25 minutes**. If you uncomment the line to run on a small sample (100 variants), the process should complete in under **2 minutes**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c049c46c67ebc",
   "metadata": {},
   "source": [
    "## Notebook Structure\n",
    "\n",
    "This notebook is organized into concise sections. Most core logic is moved to `examples/variant_effect_prediction/utils.py` and imported here:\n",
    "\n",
    "1. **Setup & Installation**: Install dependencies if needed.\n",
    "2. **Import Libraries**: Load Python libraries.\n",
    "3. **Configuration & Data Download**: Set paths/params and call `utils.download_vep_dataset` and `utils.download_ncbi_reference_genome`.\n",
    "4. **Model Selection**: Pick a model to evaluate.\n",
    "5. **Main Analysis Pipeline**: Use `utils.run_vep_analysis` to run the VEP pipeline.\n",
    "6. **Execute & Save Results**: Run the analysis and save results to a dynamically named CSV file.\n",
    "7. **Results Overview**: Quick stats and preview.\n",
    "8. **Visualization**: Plot score distributions.\n",
    "\n",
    "This keeps the notebook minimal while utilities handle the heavy lifting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e026b4088eadebc",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "This cell contains the necessary packages for running the notebook. If you have already installed them, you can skip this step. Otherwise, uncomment and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda9bbfb939574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers pandas autocuda multimolecule biopython scipy scikit-learn tqdm dill findfile requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64943f9f02cfa30",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Import all the necessary libraries for genomic data processing, model inference, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41982f35cb41cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import findfile, autocuda\n",
    "import importlib\n",
    "utils_spec = importlib.util.spec_from_file_location(\"utils\", \"utils.py\")\n",
    "utils = importlib.util.module_from_spec(utils_spec)\n",
    "utils_spec.loader.exec_module(utils)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88a2eaa3aebc72",
   "metadata": {},
   "source": [
    "## 3. Configuration & Data Download\n",
    "\n",
    "Set up the analysis parameters, file paths, and model selection here. You can easily change the `model_name` to test different genomic foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bdf1da4ceb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using utils for reusable logic\n",
    "from utils import download_ncbi_reference_genome, download_vep_dataset\n",
    "print(\"Core classes and functions imported from utils.\")\n",
    "\n",
    "local_dir = \"vep_prediction_dataset\"\n",
    "download_vep_dataset(local_dir)\n",
    "download_ncbi_reference_genome()\n",
    "\n",
    "# --- Main Configuration ---\n",
    "BED_FILE = findfile.find_cwd_file(\"variant_effects_expression.bed\")\n",
    "FASTA_FILE = findfile.find_cwd_file(\"hg38.fa\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53cea4e1ea629",
   "metadata": {},
   "source": [
    "## 4. Model Selection\n",
    "\n",
    "Choose a model to evaluate. All core processing (data loading, embeddings, scoring) is handled in `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c52a5ceb72439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Available Models for Testing ---\n",
    "AVAILABLE_MODELS = [\n",
    "    'yangheng/OmniGenome-52M',\n",
    "    'yangheng/OmniGenome-186M',\n",
    "    'yangheng/OmniGenome-v1.5',\n",
    "]\n",
    "MODEL_NAME = AVAILABLE_MODELS[0]  # Model to use for predictions\n",
    "print(f\"Selected model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe9d1c8928fa29",
   "metadata": {},
   "source": [
    "## 5. Main Analysis Pipeline\n",
    "\n",
    "Run the VEP pipeline using `utils.run_vep_analysis` for a concise workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55a7d90bdf328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main pipeline from utils for a concise demo\n",
    "from utils import run_vep_analysis\n",
    "\n",
    "print(\"Main analysis pipeline imported from utils.\")\n",
    "\n",
    "# Setup device\n",
    "compute_device = autocuda.auto_cuda()\n",
    "\n",
    "print(f\"Starting analysis on device: {compute_device}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run the analysis\n",
    "results_df = run_vep_analysis(\n",
    "    model_name=MODEL_NAME,\n",
    "    bed_file=BED_FILE,\n",
    "    fasta_file=FASTA_FILE,\n",
    "    context_size=200,  # Context size (in base pairs) to include on each side of the variant\n",
    "    batch_size=16,  # Batch size for model inference\n",
    "    device=compute_device\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Analysis completed!\")\n",
    "\n",
    "# Save results to CSV\n",
    "output_filename = f\"{MODEL_NAME.split('/')[-1]}_vep_predictions.csv\"\n",
    "results_df.to_csv(output_filename, index=False)\n",
    "print(f\"Results saved to: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f4928236089d4",
   "metadata": {},
   "source": [
    "## 6. Execute & Save Results\n",
    "\n",
    "Run the pipeline with the selected configuration and save results to a dynamically named CSV file. The filename is generated based on the selected model to avoid overwriting results from different runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e5a5de6126236",
   "metadata": {},
   "source": [
    "## 7. Results Overview\n",
    "\n",
    "Preview the results and display basic statistics for the computed distances. This provides insights into the model's sensitivity to the variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d064c07cd9709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results Summary:\")\n",
    "print(results_df[['chromosome', 'start', 'end', 'ref', 'alt', 'cls_dist', 'mut_dist']].describe())\n",
    "\n",
    "print(\"\\nFirst 5 results:\")\n",
    "display(results_df[['chromosome', 'start', 'end', 'ref', 'alt', 'cls_dist', 'mut_dist']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6e83990c0313d",
   "metadata": {},
   "source": [
    "## 8. Visualization\n",
    "\n",
    "Visualize the distributions of `cls_dist` and `mut_dist` to understand the model's behavior and sensitivity to genomic variants. These plots help identify patterns in the embeddings generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ede6861518f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.histplot(results_df['cls_dist'].dropna(), bins=50, kde=True, ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Distribution of CLS Distances')\n",
    "axes[0].set_xlabel('Cosine Distance (CLS Embedding)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(results_df['mut_dist'].dropna(), bins=50, kde=True, ax=axes[1], color='salmon')\n",
    "axes[1].set_title('Distribution of Mutation Position Distances')\n",
    "axes[1].set_xlabel('Cosine Distance (Mutation Embedding)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "[BEND: Benchmarking DNA Language Models on biologically meaningful tasks](https://arxiv.org/abs/2311.12570)\n"
   ],
   "id": "6bff0d0a156cf806"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
