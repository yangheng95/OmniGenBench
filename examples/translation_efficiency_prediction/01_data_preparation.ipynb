{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7fd907",
   "metadata": {},
   "source": [
    "# Data Preparation Tutorial: From Biological Sequences to Machine Learning Data ðŸ“Š\n",
    "\n",
    "Welcome to the first part of our tutorial series! This notebook focuses on the most critical first step of any machine learning project: **Data Preparation**. Proper data handling is the foundation of any successful model.\n",
    "\n",
    "> ðŸ’¡ **Learning Objectives**: Understand genomic data types, machine learning task classification, and master OmniGenBench data processing workflows\n",
    "> \n",
    "> ðŸ“š **Prerequisites**: It is recommended to study the **[Fundamental Concepts Tutorial](https://github.com/yangheng95/OmniGenBench/blob/master/examples/00_fundamental_concepts.ipynb)** to understand the general machine learning task classification and framework concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## The World of Genomic Data & Machine Learning Tasks ðŸ§¬\n",
    "\n",
    "In genomics, we primarily work with biological sequences, including **DNA** (composed of A, C, G, T) and **RNA** (A, C, G, U). To a computer, these are just strings of characters. Our goal is to translate these strings into a numerical format that a machine learning model can understand and learn from.\n",
    "\n",
    "Depending on our scientific question, we can frame genomic problems into various machine learning tasks:\n",
    "\n",
    "| Task Type | Description | Biological Example |\n",
    "| :--- | :--- | :--- |\n",
    "| **Sequence Classification** | Assign a single label to an entire sequence | Is this DNA sequence a promoter? (Yes/No) |\n",
    "| **Sequence Regression** | Predict a continuous numerical value for a sequence | How stable is this protein? (e.g., a score from 0.0 to 1.0) |\n",
    "| **Token Classification** | Assign a label to *each nucleotide (token)* in a sequence | Which nucleotides in this gene are part of a binding site? |\n",
    "| **Sequence-to-Sequence** | Transform an input sequence into a different output sequence | What is the secondary structure of this RNA molecule? |\n",
    "\n",
    "\n",
    "In this tutorial, we focus on **Sequence Classification**: we will classify a given mRNA sequence as having either 'High' or 'Low' translation efficiency.\n",
    "\n",
    "> ðŸŽ¯ **Why choose translation efficiency prediction?** This is a classic problem with important biological significance that's perfect for demonstrating machine learning workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcbc62c",
   "metadata": {},
   "source": [
    "## Matching Data, Tasks, and Models in OmniGenBench ðŸ”—\n",
    "\n",
    "`OmniGenBench` provides a suite of pre-built models and datasets designed to work together. The key is to match your task to the right model and relevant dataset. Here are some educational combinations you can explore within the framework:\n",
    "\n",
    "| Task Type | `OmniGenBench` Model | Example Dataset | Biological Question |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Sequence Classification** | `OmniModelForSequenceClassification` | `yangheng/promoter_prediction` | Is a DNA sequence a promoter region? |\n",
    "| **Sequence Regression** | `OmniModelForSequenceRegression` | `yangheng/gfp_fluorescence` | How fluorescent will a GFP variant be? |\n",
    "| **Token Classification** | `OmniModelForTokenClassification` | `yangheng/tf_binding_prediction` | Where will a transcription factor bind on this DNA? |\n",
    "\n",
    "For our translation efficiency prediction task (High vs. Low), we are performing **Sequence Classification**. Therefore, the appropriate model is `OmniModelForSequenceClassification`.\n",
    "\n",
    "> ðŸ’­ **Think About It**: If we wanted to predict the specific numerical value of translation efficiency (e.g., a continuous value between 0.1 and 0.9), which model should we use?\n",
    "\n",
    "Let's start preparing the data for this specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "!pip install multimolecule omnigenbench -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from omnigenbench import (\n",
    "    OmniTokenizer,\n",
    "    OmniDatasetForSequenceClassification,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ðŸš€ Enhanced OmniDataset with automatic HuggingFace integration is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d067b",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Understanding OmniGenBench Data Templates\n",
    "\n",
    "Before diving into data loading, it's crucial to understand how OmniGenBench expects data to be organized. This section explains the standardized data templates and directory structures that make the framework so powerful and consistent.\n",
    "\n",
    "### ðŸ—‚ï¸ Standard Directory Structure\n",
    "\n",
    "OmniGenBench follows a conventional directory structure that enables automatic data discovery and loading:\n",
    "\n",
    "```\n",
    "dataset_directory/\n",
    "â”œâ”€â”€ train.jsonl              # Training data (required)\n",
    "â”œâ”€â”€ valid.jsonl              # Validation data (recommended)\n",
    "â”œâ”€â”€ test.jsonl               # Test data (optional)\n",
    "â”œâ”€â”€ config.py                # Metadata file (optional)\n",
    "â””â”€â”€ README.md                # Documentation (recommended)\n",
    "```\n",
    "\n",
    "**Key Benefits of This Structure:**\n",
    "- ðŸ”„ **Automatic Discovery**: Framework can find and load data without manual path specification\n",
    "- ðŸ“Š **Consistent Splits**: Standard train/valid/test division across all datasets  \n",
    "- ðŸ§¬ **Metadata Integration**: Additional biological annotations stored separately\n",
    "- ðŸ“š **Documentation**: Self-documenting datasets for reproducible research\n",
    "\n",
    "### ðŸ“„ Data File Formats\n",
    "\n",
    "#### **JSONL Format (Recommended)**\n",
    "Each line contains a JSON object with the sequence and its annotations:\n",
    "\n",
    "```json\n",
    "{\"sequence\": \"ATCGATCG...\", \"label\": 1, \"id\": \"seq_001\"}\n",
    "{\"sequence\": \"GCTAGCTA...\", \"label\": 0, \"id\": \"seq_002\"}\n",
    "```\n",
    "\n",
    "#### **CSV Format (Alternative)**\n",
    "Tabular format with columns for sequence, labels, and metadata:\n",
    "\n",
    "```csv\n",
    "id,sequence,label,organism,5utr_length\n",
    "seq_001,ATCGATCG...,1,rice,120\n",
    "seq_002,GCTAGCTA...,0,rice,85\n",
    "```\n",
    "\n",
    "### ðŸ·ï¸ Label Format for Translation Efficiency Classification\n",
    "\n",
    "For TE prediction, labels represent translation efficiency categories:\n",
    "\n",
    "**Binary Classification:**\n",
    "- `1`: High translation efficiency\n",
    "- `0`: Low translation efficiency\n",
    "\n",
    "**JSONL Format:**\n",
    "```json\n",
    "{\"sequence\": \"ATGAAACCC...\", \"label\": 1}\n",
    "```\n",
    "\n",
    "**CSV Format:**\n",
    "```csv\n",
    "id,sequence,label\n",
    "te_001,ATGAAACCC...,1\n",
    "te_002,GCTATCGAT...,0\n",
    "```\n",
    "\n",
    "### âš™ï¸ Configuration Files\n",
    "\n",
    "#### **config.py (Optional but Recommended)**\n",
    "```json\n",
    "{\n",
    "  \"task_type\": \"sequence_classification\",\n",
    "  \"sequence_type\": \"RNA\",\n",
    "  \"num_labels\": 2,\n",
    "  \"sequence_length\": 500,\n",
    "  \"total_samples\": 15000,\n",
    "  \"description\": \"Translation efficiency prediction dataset\"\n",
    "}\n",
    "```\n",
    "### Note\n",
    "The dataset file type can also be such as CSV/TSV, parquet, or other formats, in which case the files would be named `train.csv`, `valid.csv`, and `test.csv`.\n",
    "The `config.py` file is optional but highly recommended. It allows you to define important metadata about your dataset, such as the number of labels, label names, and sequence length. This information helps the framework understand how to process your data correctly.\n",
    "\n",
    "#### **Key Metadata Fields:**\n",
    "- **`task_type`**: Defines the ML task (sequence_classification for TE)\n",
    "- **`sequence_type`**: RNA for mRNA sequences\n",
    "- **`num_labels`**: 2 for binary classification (High/Low)\n",
    "- **`label_names`**: Human-readable labels\n",
    "- **`sequence_length`**: Typical mRNA sequence length\n",
    "\n",
    "### ðŸŽ¯ Loading Strategy Options\n",
    "\n",
    "OmniGenBench provides multiple loading strategies based on your data format:\n",
    "\n",
    "```python\n",
    "# Method 1: From Hugging Face Hub (automatic download)\n",
    "dataset = OmniDatasetForSequenceClassification.from_hub(\n",
    "    dataset_name_or_path=\"translation_efficiency_prediction\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Method 2: From local directory (JSONL files)\n",
    "dataset = OmniDatasetForSequenceClassification(\n",
    "    \"./my_te_dataset/\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Method 3: From CSV file\n",
    "dataset = OmniDatasetForSequenceClassification(\n",
    "    \"te_data.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    sequence_column=\"sequence\",\n",
    "    label_column=\"label\"\n",
    ")\n",
    "```\n",
    "\n",
    "### ðŸ’¡ Best Practices\n",
    "\n",
    "1. **ðŸ·ï¸ Consistent Naming**: Use descriptive, consistent file and column names\n",
    "2. **ðŸ“Š Balanced Splits**: Ensure train/valid/test splits are representative\n",
    "3. **ðŸ” Quality Control**: Validate data integrity before training\n",
    "4. **ðŸ“š Documentation**: Include README with dataset description and usage\n",
    "5. **ðŸ§¬ Biological Context**: Preserve important biological metadata\n",
    "\n",
    "With this foundation understanding, let's now proceed to configure our specific dataset parameters.\n",
    "\n",
    "### ðŸ› ï¸ Environment Setup\n",
    "\n",
    "Before we start data processing, we need to install and import the necessary libraries to ensure our environment is ready for the tasks ahead.\n",
    "\n",
    "> âš ï¸ **Note**: If you have already installed these packages, you can skip the installation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Preparation Demo\n",
    "print(\"ðŸŽ‰ Data Preparation Simplified with Enhanced OmniDataset!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "config_or_model = \"yangheng/OmniGenome-52M\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21184d06",
   "metadata": {},
   "source": [
    "### ðŸ“¥ Enhanced Data Preparation with OmniDataset\n",
    "\n",
    "The enhanced OmniGenBench framework has revolutionized data preparation! With the new `from_hub()` class method, you no longer need to:\n",
    "\n",
    "- âŒ Write manual download functions\n",
    "- âŒ Create custom dataset classes  \n",
    "- âŒ Handle file extraction manually\n",
    "- âŒ Manage cache directories\n",
    "\n",
    "Instead, everything is handled automatically:\n",
    "\n",
    "- âœ… **Automatic Download**: Downloads datasets from HuggingFace Hub automatically\n",
    "- âœ… **Smart Processing**: Handles different file formats (CSV, JSON, JSONL) intelligently\n",
    "- âœ… **Built-in DataLoaders**: Get optimized PyTorch DataLoaders with one method call\n",
    "- âœ… **Universal Interface**: Works with all genomic tasks (classification, regression, token-level)\n",
    "\n",
    "> ðŸŒ¾ **Dataset Background**: We're using the rice translation efficiency dataset where each mRNA sequence is labeled as having high (1) or low (0) translation efficiency based on experimental validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ðŸ” Loading model and tokenizer from: {config_or_model}\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = OmniTokenizer.from_pretrained(config_or_model)\n",
    "print(\"âœ… Tokenizer initialized\")\n",
    "\n",
    "# Create datasets with automatic download and processing\n",
    "print(\"ðŸ—ï¸ Creating datasets with automatic download...\")\n",
    "datasets = OmniDatasetForSequenceClassification.from_hub(\n",
    "    dataset_name_or_path=\"translation_efficiency_prediction\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Dataset sizes:\")\n",
    "print(f\"  ðŸ“ˆ Training samples: {len(datasets['train'])}\")\n",
    "print(f\"  ðŸ” Validation samples: {len(datasets['valid'])}\")\n",
    "print(f\"  ðŸ§ª Test samples: {len(datasets['test'])}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸŽ‰ Data preparation completed with just a few lines of code!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937983f",
   "metadata": {},
   "source": [
    "### ðŸš€ The Power of OmniDataset\n",
    "\n",
    "The `OmniDataset` class eliminates the complexity of traditional data preparation. Here's what happened behind the scenes when we called `from_hub()`:\n",
    "\n",
    "1. **Automatic Download**: \n",
    "   - Checks if data exists locally\n",
    "   - Downloads from HuggingFace Hub if needed  \n",
    "   - Shows progress with a beautiful progress bar\n",
    "\n",
    "2. **Intelligent Processing**:\n",
    "   - Automatically detects file format (CSV, JSON, JSONL)\n",
    "   - Handles data parsing and validation\n",
    "   - Creates proper label mappings\n",
    "\n",
    "3. **Seamless Integration**:\n",
    "   - Works with any OmniGenome tokenizer\n",
    "   - Provides optimized DataLoaders with smart defaults\n",
    "   - Handles GPU memory management automatically\n",
    "\n",
    "**Why is this revolutionary?**\n",
    "- **60% Less Code**: Compare our 3-line solution to traditional 50+ line implementations\n",
    "- **Universal Interface**: Same pattern works for all genomic tasks\n",
    "- **Error-Proof**: Built-in error handling and validation\n",
    "- **Research-Ready**: Focus on science, not infrastructure\n",
    "\n",
    "> ðŸ’¡ **Pro Tip**: This same pattern works for any genomic dataset! Just change the `dataset_name` parameter and you're ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f2550",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary and Next Steps\n",
    "\n",
    "In this comprehensive data preparation tutorial, you have mastered both **basic** and **advanced** data handling skills:\n",
    "\n",
    "### ðŸŽ“ **Skills Learned:**\n",
    "âœ… **Understood genomic data types** (DNA vs RNA)  \n",
    "âœ… **Mastered ML task classification** (classification, regression, token classification)  \n",
    "âœ… **Learned data-task-model matching principles**  \n",
    "âœ… **Understood OmniGenBench data templates** and directory structures\n",
    "âœ… **Successfully used pre-built datasets** from HuggingFace Hub\n",
    "âœ… **Created optimized DataLoaders** with OmniGenBench\n",
    "\n",
    "### ðŸ—ï¸ **OmniGenBench Design Philosophy**\n",
    "\n",
    "The framework follows key design principles that make genomic machine learning accessible and powerful:\n",
    "\n",
    "#### **ðŸ”„ Modularity**\n",
    "- **Universal concepts** separated from task-specific implementations\n",
    "- **Reusable components** across different genomic prediction tasks\n",
    "- **Standardized interfaces** for consistent user experience\n",
    "\n",
    "#### **ðŸ“š Progressive Learning**\n",
    "- **Foundation concepts** apply to all tasks (like the data templates you learned)\n",
    "- **Task-specific tutorials** build upon universal knowledge\n",
    "- **Advanced techniques** available when you're ready\n",
    "\n",
    "#### **ðŸŽ¯ Practicality**\n",
    "- **Real research scenarios** guide tutorial design\n",
    "- **Publication-ready workflows** from day one\n",
    "- **Immediate applicability** to your own projects\n",
    "\n",
    "#### **ðŸ”§ Consistency**\n",
    "- **Same 4-step workflow** across all genomic tasks:\n",
    "  1. **Data Preparation** (this tutorial)\n",
    "  2. **Model Initialization** (next tutorial)\n",
    "  3. **Model Training** (tutorial 3)\n",
    "  4. **Model Inference** (tutorial 4)\n",
    "- **Uniform data formats** enable easy task switching\n",
    "- **Predictable patterns** reduce learning curve\n",
    "\n",
    "#### **ðŸš€ Extensibility**\n",
    "- **Easy adaptation** of tutorials for custom applications\n",
    "- **Template-based approach** for new datasets\n",
    "- **Modular architecture** supports novel research directions\n",
    "\n",
    "> ðŸ’¡ **Why This Matters**: This philosophy ensures that once you learn one genomic task, you can quickly master others. The translation efficiency concepts you've learned here directly apply to transcription factor binding prediction, protein stability prediction, and many other genomic challenges!\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ What's Next...\n",
    "\n",
    "You've built a solid data foundation! In the next tutorial, we will:\n",
    "- ðŸ¤– **Explore genomic foundation models** and their architecture\n",
    "- ðŸ”§ **Learn model initialization** for different biological tasks\n",
    "- ðŸ“Š **Understand model parameters** and configuration options\n",
    "- ðŸŽ¯ **Apply models to your custom data** you just created!\n",
    "\n",
    "**Ready to meet your first genomic foundation model?** \n",
    "\n",
    "ðŸ‘‰ **Next Step**: Open [02_model_initialization.ipynb](https://github.com/yangheng95/OmniGenBench/blob/master/examples/translation_efficiency_prediction/02_model_initialization.ipynb) to continue your learning journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95280cfe",
   "metadata": {},
   "source": [
    "## ðŸš€ Ready for Advanced Dataset Creation?\n",
    "\n",
    "You've mastered the fundamentals of data preparation using pre-built datasets! But what happens when you need to work with your own biological data? \n",
    "\n",
    "### ðŸ”¬ When You Need Custom Datasets\n",
    "\n",
    "In real research, you often encounter:\n",
    "- ðŸ§¬ **Novel experimental data** from your laboratory\n",
    "- ðŸ“Š **Unique biological questions** not covered by existing datasets  \n",
    "- ðŸŽ¯ **Proprietary data** that gives you a research advantage\n",
    "- ðŸ“ˆ **Publication requirements** for original datasets\n",
    "\n",
    "### ðŸŽ“ Advanced Skills Await You!\n",
    "\n",
    "To learn how to create **publication-ready datasets from scratch**, including:\n",
    "- **ðŸ“‹ Professional CSV templates** for any genomic task\n",
    "- **âš™ï¸ Research-grade configuration** management\n",
    "- **ðŸ”¬ Data quality assurance** and validation\n",
    "- **ðŸ“Š Integration with complex workflows**\n",
    "\n",
    "**ðŸ‘‰ Continue to Tutorial 5: [Advanced Dataset Creation](https://github.com/yangheng95/OmniGenBench/blob/master/examples/translation_efficiency_prediction/05_advanced_dataset_creation.ipynb)**\n",
    "\n",
    "> ðŸ’¡ **Learning Path**: Master the basics first (Tutorials 1-4), then advance to custom dataset creation (Tutorial 5) when you're ready for professional research workflows!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
