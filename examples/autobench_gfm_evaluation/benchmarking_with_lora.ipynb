{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420f6ebf1395838",
   "metadata": {},
   "source": [
    "# 🧬 Automated Genomic Foundation Model Benchmarking with OmniGenBench\n",
    "\n",
    "Welcome to this comprehensive tutorial where we'll explore how to **systematically evaluate genomic foundation models** using **OmniGenBench's AutoBench framework**. This guide will walk you through automated benchmarking, parameter-efficient fine-tuning with LoRA, and comprehensive performance analysis across multiple genomic tasks.\n",
    "\n",
    "### 1. The Evaluation Challenge: Why Benchmark Genomic Foundation Models?\n",
    "\n",
    "**Genomic Foundation Model (GFM) benchmarking** is crucial for understanding model capabilities and selecting the best models for specific applications. Systematic evaluation addresses several critical needs:\n",
    "\n",
    "- **Model Selection**: Comparing different foundation models to choose the optimal one for your task\n",
    "- **Performance Validation**: Ensuring models perform reliably across diverse genomic tasks\n",
    "- **Efficiency Analysis**: Understanding computational trade-offs between model size and performance\n",
    "- **Research Advancement**: Contributing to the scientific understanding of genomic AI capabilities\n",
    "\n",
    "The challenge lies in the diversity of genomic tasks and the computational cost of comprehensive evaluation. This is where automated benchmarking becomes essential.\n",
    "\n",
    "### 2. The Solution: AutoBench Framework\n",
    "\n",
    "**AutoBench** is OmniGenBench's automated evaluation system that provides:\n",
    "\n",
    "- **Standardized Benchmarks**: Curated datasets covering diverse genomic tasks (GUE, RGB suites)\n",
    "- **Parameter-Efficient Fine-tuning**: LoRA integration for efficient model adaptation\n",
    "- **Automated Pipeline**: End-to-end evaluation with minimal manual intervention\n",
    "- **Comprehensive Metrics**: Multiple evaluation metrics and statistical analysis\n",
    "- **Scalable Evaluation**: Support for evaluating multiple models across multiple tasks\n",
    "\n",
    "**Benchmark Suites:**\n",
    "\n",
    "| Benchmark Suite | Tasks | Focus Area |\n",
    "|----------------|--------|------------|\n",
    "| **GUE** (Genomic Understanding Evaluation) | DNA/Protein tasks | Basic genomic understanding |\n",
    "| **RGB** (RNA Genome Benchmark) | RNA-specific tasks | RNA biology and function |\n",
    "\n",
    "### 3. The Tool: LoRA + AutoBench Integration\n",
    "\n",
    "#### Parameter-Efficient Fine-Tuning with LoRA\n",
    "**Low-Rank Adaptation (LoRA)** enables efficient fine-tuning of large genomic foundation models by:\n",
    "\n",
    "1. **Freezing Base Model**: Original model weights remain unchanged\n",
    "2. **Low-Rank Decomposition**: Adding small trainable matrices to transformer layers\n",
    "3. **Reduced Parameters**: Dramatically fewer trainable parameters (~0.1-1% of original)\n",
    "4. **Task Switching**: Easy switching between different task-specific adapters\n",
    "\n",
    "#### AutoBench Integration\n",
    "The integration provides:\n",
    "- **Automated LoRA Configuration**: Optimal LoRA parameters for genomic tasks\n",
    "- **Batch Processing**: Evaluate multiple models and tasks simultaneously\n",
    "- **Resource Management**: Efficient GPU memory usage and training optimization\n",
    "- **Result Aggregation**: Comprehensive performance reporting and analysis\n",
    "\n",
    "### 4. The Workflow: A 4-Step Guide to Automated Benchmarking\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"4-Step Workflow for Automated GFM Benchmarking\"\n",
    "        A[\"📥 Step 1: Setup and Configuration<br/>Configure benchmarks, models, and LoRA parameters\"] --> B[\"🔧 Step 2: Model Loading and Preparation<br/>Load foundation models and initialize AutoBench\"]\n",
    "        B --> C[\"🎓 Step 3: Automated Benchmarking<br/>Run systematic evaluation across tasks and models\"]\n",
    "        C --> D[\"🔮 Step 4: Analysis and Interpretation<br/>Analyze results and derive insights\"]\n",
    "    end\n",
    "\n",
    "    style A fill:#e1f5fe,stroke:#333,stroke-width:2px\n",
    "    style B fill:#f3e5f5,stroke:#333,stroke-width:2px\n",
    "    style C fill:#e8f5e8,stroke:#333,stroke-width:2px\n",
    "    style D fill:#fff3e0,stroke:#333,stroke-width:2px\n",
    "```\n",
    "\n",
    "Let's start systematically evaluating genomic foundation models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f9512a24bdba8",
   "metadata": {},
   "source": [
    "## 🚀 Step 1: Setup and Configuration\n",
    "\n",
    "This first step focuses on setting up our automated benchmarking environment and configuring the evaluation parameters.\n",
    "\n",
    "### 1.1: Environment Setup\n",
    "\n",
    "First, let's install the required packages for automated benchmarking with LoRA fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740c7d05f60e109",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "First, let's ensure all the required packages are installed. If you have already installed them, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf78b6c369b55ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install omnigenbench peft bitsandbytes -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a6643958f6d06",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Import all the necessary libraries for the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fb04a84df87efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangheng/miniconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **@@ #========= @@**            ___                     _\n",
      "      **@@ +----- @@**             / _ \\  _ __ ___   _ __  (_)\n",
      "        **@@ = @@**               | | | || '_ ` _ \\ | '_ \\ | |\n",
      "           **@@                   | |_| || | | | | || | | || |\n",
      "        @@** = **@@                \\___/ |_| |_| |_||_| |_||_|\n",
      "     @@** ------+ **@@\n",
      "   @@** =========# **@@            ____\n",
      "  @@ ---------------+ @@          / ___|  ___  _ __\n",
      " @@ ================== @@        | |  _  / _ \\| '_ \\\n",
      "  @@ +--------------- @@         | |_| ||  __/| | | |\n",
      "   @@** #========= **@@           \\____| \\___||_| |_|\n",
      "    @@** +------ **@@\n",
      "       @@** = **@@\n",
      "          @@**                    ____                      _\n",
      "       **@@ = @@**               | __ )   ___  _ __    ___ | |__\n",
      "    **@@ -----+  @@**            |  _ \\  / _ \\| '_ \\  / __|| '_ \\\n",
      "  **@@ ==========# @@**          | |_) ||  __/| | | || (__ | | | |\n",
      "  @@ --------------+ @@**        |____/  \\___||_| |_| \\___||_| |_|\n",
      "\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from omnigenbench import AutoBench\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6c46c392be2c3",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "This section contains all the settings for the LoRA fine-tuning experiment. You can easily modify these parameters to test different models, benchmarks, or LoRA settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e8a7e16659a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  - GFM to Tune: yangheng/OmniGenome-52M\n",
      "  - Benchmark: RGB\n",
      "  - Epochs: 1\n",
      "  - LoRA Config: {'r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['key', 'value', 'dense'], 'bias': 'none'}\n"
     ]
    }
   ],
   "source": [
    "# --- General Settings ---\n",
    "BENCHMARK = \"RGB\"  # Benchmark suite to use, e.g., \"GUE\", \"RGB\"\n",
    "BATCH_SIZE = 8\n",
    "PATIENCE = 3\n",
    "EPOCHS = 1\n",
    "MAX_EXAMPLES = 1000  # Use a smaller number for quick testing, set to None for all data\n",
    "SEED = random.randint(0, 1000)\n",
    "\n",
    "# --- Model Selection ---\n",
    "# Choose the Genomic Foundation Model (GFM) to fine-tune\n",
    "GFM_TO_TUNE = 'yangheng/OmniGenome-52M'\n",
    "\n",
    "# List of available GFMs for testing\n",
    "AVAILABLE_GFMS = [\n",
    "    'yangheng/OmniGenome-52M',\n",
    "    # 'yangheng/OmniGenome-186M',\n",
    "    # 'yangheng/OmniGenome-v1.5',\n",
    "    # 'zhihan1996/DNABERT-2-117M',\n",
    "    # 'LongSafari/hyenadna-large-1m-seqlen-hf',\n",
    "    # 'InstaDeepAI/nucleotide-transformer-v2-100m-multi-species',\n",
    "    # 'kuleshov-group/caduceus-ph_seqlen-131k_d_model-256_n_layer-16',\n",
    "    # 'multimolecule/rnafm',\n",
    "\n",
    "    # Evo models, you need to install the `evo` package according to the official documentation\n",
    "    # 'arcinstitute/evo-1-131k-base',\n",
    "    # 'SpliceBERT-510nt',\n",
    "]\n",
    "GFM = GFM_TO_TUNE.split('/')[-1]\n",
    "# --- LoRA Configuration ---\n",
    "# This dictionary contains LoRA settings for different models.\n",
    "# `r`: The rank of the update matrices.\n",
    "# `lora_alpha`: The scaling factor.\n",
    "# `lora_dropout`: The dropout probability for LoRA layers.\n",
    "# `target_modules`: The modules (e.g., attention blocks) to apply LoRA to.\n",
    "LORA_CONFIGS = {\n",
    "    \"OmniGenome-52M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"OmniGenome-186M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"caduceus-ph_seqlen-131k_d_model-256_n_layer-16\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"in_proj\", \"x_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnamsm\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnafm\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnabert\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"agro-nucleotide-transformer-1b\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"SpliceBERT-510nt\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"DNABERT-2-117M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"Wqkv\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"3utrbert\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"hyenadna-large-1m-seqlen-hf\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"in_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"nucleotide-transformer-v2-100m-multi-species\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1-131k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"mlp\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1.5-8k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1-8k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo2_7b\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            # \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  - GFM to Tune: {GFM_TO_TUNE}\")\n",
    "print(f\"  - Benchmark: {BENCHMARK}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - LoRA Config: {LORA_CONFIGS.get(GFM, LORA_CONFIGS[GFM])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89951b937ccc2cc2",
   "metadata": {},
   "source": [
    "## 4. Model-Specific Loading\n",
    "\n",
    "Different GFMs may require specific loading procedures. This function handles these special cases, particularly for models like `multimolecule` or `evo` which might have custom tokenizers or model classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e1e3f7c5cd7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading function defined.\n"
     ]
    }
   ],
   "source": [
    "def load_gfm_and_tokenizer(gfm_name):\n",
    "    \"\"\"Loads a GFM and its tokenizer, handling special cases.\"\"\"\n",
    "    print(f\"\\nLoading model and tokenizer for: {gfm_name}\")\n",
    "    \n",
    "    if 'multimolecule' in gfm_name:\n",
    "        from multimolecule import RnaTokenizer, AutoModelForTokenPrediction\n",
    "        tokenizer = RnaTokenizer.from_pretrained(gfm_name)\n",
    "        model = AutoModelForTokenPrediction.from_pretrained(gfm_name, trust_remote_code=True).base_model\n",
    "        print(\"Loaded multimolecule model with custom classes.\")\n",
    "        \n",
    "    elif 'evo-1' in gfm_name:\n",
    "        # Using transformers to load Evo models\n",
    "        config = AutoConfig.from_pretrained(gfm_name, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(gfm_name, config=config, trust_remote_code=True).backbone\n",
    "        tokenizer = AutoTokenizer.from_pretrained(gfm_name, trust_remote_code=True)\n",
    "        tokenizer.pad_token_id = tokenizer.pad_token_type_id\n",
    "        \n",
    "        # Patch for the unembedding layer\n",
    "        model.config = config\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.unembed.unembed = lambda x: x\n",
    "        print(\"Loaded Evo model with custom patching.\")\n",
    "        \n",
    "    else:\n",
    "        # Default loading for most Hugging Face models\n",
    "        tokenizer = None  # Let AutoBench handle it\n",
    "        model = gfm_name\n",
    "        print(\"Using standard model name for AutoBench.\")\n",
    "        \n",
    "    return model, tokenizer\n",
    "\n",
    "print(\"Model loading function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43542679a9d3b7f9",
   "metadata": {},
   "source": [
    "## 5. Running LoRA Fine-tuning\n",
    "\n",
    "Now, we'll execute the LoRA fine-tuning process for the selected model. `AutoBench` handles the entire workflow, from data loading and preprocessing to training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818720a64f31f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model and tokenizer for: yangheng/OmniGenome-52M\n",
      "Using standard model name for AutoBench.\n",
      "\n",
      "Initializing AutoBench for benchmark: RGB\n",
      "FindFile Warning --> multiple targets ['__OMNIGENOME_DATA__/benchmarks/RGB', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMD', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMR', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-rnastralign', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-mRNA', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Strand2', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-bpRNA', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Archive2', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Arabidopsis', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Rice', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Arabidopsis', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Rice'] found, only return the shortest path: <__OMNIGENOME_DATA__/benchmarks/RGB>\n",
      "[2025-11-01 15:12:28.248] [omnigenbench 0.3.27alpha]  Benchmark: RGB found in __OMNIGENOME_DATA__/benchmarks/RGB.\n",
      "[2025-11-01 15:12:28.255] [omnigenbench 0.3.27alpha]  Benchmark metadata version: 0.2.0alpha\n",
      "[2025-11-01 15:12:28.259] [omnigenbench 0.3.27alpha]  Loaded benchmarks:  ['RNA-mRNA', 'RNA-SNMD', 'RNA-SNMR', 'RNA-SSP-Archive2', 'RNA-SSP-rnastralign', 'RNA-SSP-bpRNA', 'RNA-TE-Prediction.Arabidopsis', 'RNA-TE-Prediction.Rice', 'RNA-Region-Classification.Arabidopsis', 'RNA-Region-Classification.Rice']\n",
      "[2025-11-01 15:12:28.263] [omnigenbench 0.3.27alpha]  Benchmark Root: __OMNIGENOME_DATA__/benchmarks/RGB\n",
      "Benchmark List: ['RNA-mRNA', 'RNA-SNMD', 'RNA-SNMR', 'RNA-SSP-Archive2', 'RNA-SSP-rnastralign', 'RNA-SSP-bpRNA', 'RNA-TE-Prediction.Arabidopsis', 'RNA-TE-Prediction.Rice', 'RNA-Region-Classification.Arabidopsis', 'RNA-Region-Classification.Rice']\n",
      "Model Name or Path: OmniGenome-52M\n",
      "Tokenizer: None\n",
      "Metric Visualizer Path: ./autobench_evaluations/RGB-OmniGenome-52M-20251101_151228.mv\n",
      "BenchConfig Details: <module 'bench_metadata' from '/home/yangheng/omnigenome/examples/autobench_gfm_evaluation/__OMNIGENOME_DATA__/benchmarks/RGB/metadata.py'>\n",
      "\n",
      "\n",
      "Starting LoRA fine-tuning for yangheng/OmniGenome-52M...\n",
      "[2025-11-01 15:12:28.271] [omnigenbench 0.3.27alpha]  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \n",
      "Running evaluation for task: RNA-mRNA Progress:  1 / 10 10.0%\n",
      "FindFile Warning --> multiple targets ['__OMNIGENOME_DATA__/benchmarks/RGB/metadata.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMD/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMD/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMD/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMD/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMR/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMR/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMR/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SNMR/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-rnastralign/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-rnastralign/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-rnastralign/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-rnastralign/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-mRNA/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-mRNA/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-mRNA/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Strand2/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Strand2/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Strand2/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Strand2/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-bpRNA/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-bpRNA/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-bpRNA/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-bpRNA/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/__pycache__/metadata.cpython-312.pyc', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Archive2/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Archive2/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Archive2/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-SSP-Archive2/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Arabidopsis/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Arabidopsis/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Arabidopsis/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Arabidopsis/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Rice/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Rice/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Rice/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-TE-Prediction/Rice/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Arabidopsis/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Arabidopsis/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Arabidopsis/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Arabidopsis/config.py', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Rice/train.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Rice/test.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Rice/valid.json', '__OMNIGENOME_DATA__/benchmarks/RGB/RNA-Region-Classification/Rice/config.py'] found, only return the shortest path: <__OMNIGENOME_DATA__/benchmarks/RGB/metadata.py>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find AutoConfig instance in __OMNIGENOME_DATA__/benchmarks/RGB/metadata.py",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Run the benchmark with LoRA fine-tuning\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting LoRA fine-tuning for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGFM_TO_TUNE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mbench\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_EXAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the LoRA config here\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 LoRA fine-tuning complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCheck the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mautobench_logs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mautobench_evaluations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directories for results.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/omnigenbench/auto/auto_bench/auto_bench.py:239\u001b[39m, in \u001b[36mAutoBench.run\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m         bench_config = attr\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bench_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    240\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find AutoConfig instance in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbench_config_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m     )\n\u001b[32m    242\u001b[39m fprint(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded config for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbench\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbench_config_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    243\u001b[39m fprint(bench_config)\n",
      "\u001b[31mValueError\u001b[39m: Could not find AutoConfig instance in __OMNIGENOME_DATA__/benchmarks/RGB/metadata.py"
     ]
    }
   ],
   "source": [
    "# Load the selected model and tokenizer\n",
    "model, tokenizer = load_gfm_and_tokenizer(GFM_TO_TUNE)\n",
    "\n",
    "# Initialize AutoBench\n",
    "print(f\"\\nInitializing AutoBench for benchmark: {BENCHMARK}\")\n",
    "bench = AutoBench(\n",
    "    benchmark=BENCHMARK,\n",
    "    config_or_model=GFM_TO_TUNE,\n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True,\n",
    "    trainer='native',  # 'native' or 'accelerate'\n",
    "    autocast='fp16',  # 'fp16', 'bf16', or 'fp32'\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "# Get the appropriate LoRA config\n",
    "lora_config = LORA_CONFIGS.get(GFM, LORA_CONFIGS[GFM])\n",
    "\n",
    "# Run the benchmark with LoRA fine-tuning\n",
    "print(f\"\\nStarting LoRA fine-tuning for {GFM_TO_TUNE}...\")\n",
    "bench.run(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    patience=PATIENCE,\n",
    "    max_examples=MAX_EXAMPLES,\n",
    "    seeds=SEED,\n",
    "    epochs=EPOCHS,\n",
    "    lora_config=lora_config, # Pass the LoRA config here\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 LoRA fine-tuning complete!\")\n",
    "print(\"Check the 'autobench_logs' and 'autobench_evaluations' directories for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386249fc8fc35efa",
   "metadata": {},
   "source": [
    "## 6. Multi-Model LoRA Fine-tuning (Optional)\n",
    "\n",
    "The following section demonstrates how to automate the LoRA fine-tuning process for a list of GFMs. Uncomment and run this cell to compare the performance of multiple models with LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89dd9373b6a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this cell to run LoRA fine-tuning for multiple models\n",
    "\n",
    "# print(\"Starting multi-model LoRA fine-tuning...\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# for gfm in AVAILABLE_GFMS:\n",
    "#     try:\n",
    "#         # Load model and tokenizer\n",
    "#         model, tokenizer = load_gfm_and_tokenizer(gfm)\n",
    "\n",
    "#         # Initialize AutoBench\n",
    "#         print(f\"\\nInitializing AutoBench for {gfm} on {BENCHMARK}\")\n",
    "#         bench = AutoBench(\n",
    "#             benchmark=BENCHMARK,\n",
    "#             config_or_model=model,\n",
    "#             tokenizer=tokenizer,\n",
    "#             overwrite=True,\n",
    "#             trainer='native',\n",
    "#             autocast='fp16',\n",
    "#             device='cuda',\n",
    "#         )\n",
    "\n",
    "#         # Get the appropriate LoRA config\n",
    "#         lora_config = LORA_CONFIGS.get(gfm.split('/')[-1], LORA_CONFIGS['default'])\n",
    "\n",
    "#         # Run the benchmark\n",
    "#         print(f\"\\nStarting LoRA fine-tuning for {gfm}...\")\n",
    "#         bench.run(\n",
    "#             batch_size=BATCH_SIZE,\n",
    "#             patience=PATIENCE,\n",
    "#             max_examples=MAX_EXAMPLES,\n",
    "#             seeds=SEED,\n",
    "#             epochs=EPOCHS,\n",
    "#             lora_config=lora_config,\n",
    "#         )\n",
    "#         print(f\"\\n✅ Finished fine-tuning for {gfm}.\")\n",
    "#         print(\"=\"*50)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n❌ An error occurred while processing {gfm}: {e}\")\n",
    "#         print(\"=\"*50)\n",
    "#         continue\n",
    "\n",
    "# print(\"\\n🎉 All models have been processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
