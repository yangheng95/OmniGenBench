{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420f6ebf1395838",
   "metadata": {},
   "source": [
    "# üß¨ Automated Genomic Foundation Model Benchmarking with OmniGenBench\n",
    "\n",
    "Welcome to this comprehensive tutorial where we'll explore how to **systematically evaluate genomic foundation models** using **OmniGenBench's AutoBench framework**. This guide will walk you through automated benchmarking, parameter-efficient fine-tuning with LoRA, and comprehensive performance analysis across multiple genomic tasks.\n",
    "\n",
    "### 1. The Evaluation Challenge: Why Benchmark Genomic Foundation Models?\n",
    "\n",
    "**Genomic Foundation Model (GFM) benchmarking** is crucial for understanding model capabilities and selecting the best models for specific applications. Systematic evaluation addresses several critical needs:\n",
    "\n",
    "- **Model Selection**: Comparing different foundation models to choose the optimal one for your task\n",
    "- **Performance Validation**: Ensuring models perform reliably across diverse genomic tasks\n",
    "- **Efficiency Analysis**: Understanding computational trade-offs between model size and performance\n",
    "- **Research Advancement**: Contributing to the scientific understanding of genomic AI capabilities\n",
    "\n",
    "The challenge lies in the diversity of genomic tasks and the computational cost of comprehensive evaluation. This is where automated benchmarking becomes essential.\n",
    "\n",
    "### 2. The Solution: AutoBench Framework\n",
    "\n",
    "**AutoBench** is OmniGenBench's automated evaluation system that provides:\n",
    "\n",
    "- **Standardized Benchmarks**: Curated datasets covering diverse genomic tasks (GUE, RGB suites)\n",
    "- **Parameter-Efficient Fine-tuning**: LoRA integration for efficient model adaptation\n",
    "- **Automated Pipeline**: End-to-end evaluation with minimal manual intervention\n",
    "- **Comprehensive Metrics**: Multiple evaluation metrics and statistical analysis\n",
    "- **Scalable Evaluation**: Support for evaluating multiple models across multiple tasks\n",
    "\n",
    "**Benchmark Suites:**\n",
    "\n",
    "| Benchmark Suite | Tasks | Focus Area |\n",
    "|----------------|--------|------------|\n",
    "| **GUE** (Genomic Understanding Evaluation) | DNA/Protein tasks | Basic genomic understanding |\n",
    "| **RGB** (RNA Genome Benchmark) | RNA-specific tasks | RNA biology and function |\n",
    "\n",
    "### 3. The Tool: LoRA + AutoBench Integration\n",
    "\n",
    "#### Parameter-Efficient Fine-Tuning with LoRA\n",
    "**Low-Rank Adaptation (LoRA)** enables efficient fine-tuning of large genomic foundation models by:\n",
    "\n",
    "1. **Freezing Base Model**: Original model weights remain unchanged\n",
    "2. **Low-Rank Decomposition**: Adding small trainable matrices to transformer layers\n",
    "3. **Reduced Parameters**: Dramatically fewer trainable parameters (~0.1-1% of original)\n",
    "4. **Task Switching**: Easy switching between different task-specific adapters\n",
    "\n",
    "#### AutoBench Integration\n",
    "The integration provides:\n",
    "- **Automated LoRA Configuration**: Optimal LoRA parameters for genomic tasks\n",
    "- **Batch Processing**: Evaluate multiple models and tasks simultaneously\n",
    "- **Resource Management**: Efficient GPU memory usage and training optimization\n",
    "- **Result Aggregation**: Comprehensive performance reporting and analysis\n",
    "\n",
    "### 4. The Workflow: A 4-Step Guide to Automated Benchmarking\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph \"4-Step Workflow for Automated GFM Benchmarking\"\n",
    "        A[\"üì• Step 1: Setup and Configuration<br/>Configure benchmarks, models, and LoRA parameters\"] --> B[\"üîß Step 2: Model Loading and Preparation<br/>Load foundation models and initialize AutoBench\"]\n",
    "        B --> C[\"üéì Step 3: Automated Benchmarking<br/>Run systematic evaluation across tasks and models\"]\n",
    "        C --> D[\"üîÆ Step 4: Analysis and Interpretation<br/>Analyze results and derive insights\"]\n",
    "    end\n",
    "\n",
    "    style A fill:#e1f5fe,stroke:#333,stroke-width:2px\n",
    "    style B fill:#f3e5f5,stroke:#333,stroke-width:2px\n",
    "    style C fill:#e8f5e8,stroke:#333,stroke-width:2px\n",
    "    style D fill:#fff3e0,stroke:#333,stroke-width:2px\n",
    "```\n",
    "\n",
    "Let's start systematically evaluating genomic foundation models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f9512a24bdba8",
   "metadata": {},
   "source": [
    "## üöÄ Step 1: Setup and Configuration\n",
    "\n",
    "This first step focuses on setting up our automated benchmarking environment and configuring the evaluation parameters.\n",
    "\n",
    "### 1.1: Environment Setup\n",
    "\n",
    "First, let's install the required packages for automated benchmarking with LoRA fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740c7d05f60e109",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "First, let's ensure all the required packages are installed. If you have already installed them, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "id": "cf78b6c369b55ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:53:04.344457Z",
     "start_time": "2025-11-08T08:51:55.669717Z"
    }
   },
   "source": [
    "!pip install omnigenbench peft bitsandbytes -U -q"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "776a6643958f6d06",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Import all the necessary libraries for the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "id": "b3fb04a84df87efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:55:42.600149Z",
     "start_time": "2025-11-08T08:55:21.168084Z"
    }
   },
   "source": [
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from omnigenbench import AutoBench\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hengu\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\src\\misc\\utils.py:370: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "\n",
      "    **@@ #========= @@**            ___                     _\n",
      "      **@@ +----- @@**             / _ \\  _ __ ___   _ __  (_)\n",
      "        **@@ = @@**               | | | || '_ ` _ \\ | '_ \\ | |\n",
      "           **@@                   | |_| || | | | | || | | || |\n",
      "        @@** = **@@                \\___/ |_| |_| |_||_| |_||_|\n",
      "     @@** ------+ **@@\n",
      "   @@** =========# **@@            ____\n",
      "  @@ ---------------+ @@          / ___|  ___  _ __\n",
      " @@ ================== @@        | |  _  / _ \\| '_ \\\n",
      "  @@ +--------------- @@         | |_| ||  __/| | | |\n",
      "   @@** #========= **@@           \\____| \\___||_| |_|\n",
      "    @@** +------ **@@\n",
      "       @@** = **@@\n",
      "          @@**                    ____                      _\n",
      "       **@@ = @@**               | __ )   ___  _ __    ___ | |__\n",
      "    **@@ -----+  @@**            |  _ \\  / _ \\| '_ \\  / __|| '_ \\\n",
      "  **@@ ==========# @@**          | |_) ||  __/| | | || (__ | | | |\n",
      "  @@ --------------+ @@**        |____/  \\___||_| |_| \\___||_| |_|\n",
      "\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b1d6c46c392be2c3",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "This section contains all the settings for the LoRA fine-tuning experiment. You can easily modify these parameters to test different models, benchmarks, or LoRA settings."
   ]
  },
  {
   "cell_type": "code",
   "id": "d1e8a7e16659a8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:56:29.006174Z",
     "start_time": "2025-11-08T08:56:28.957788Z"
    }
   },
   "source": [
    "# --- General Settings ---\n",
    "BENCHMARK = \"RGB\"  # Benchmark suite to use, e.g., \"GUE\", \"RGB\"\n",
    "BATCH_SIZE = 8\n",
    "PATIENCE = 3\n",
    "EPOCHS = 1\n",
    "MAX_EXAMPLES = 1000  # Use a smaller number for quick testing, set to None for all data\n",
    "SEED = random.randint(0, 1000)\n",
    "\n",
    "# --- Model Selection ---\n",
    "# Choose the Genomic Foundation Model (GFM) to fine-tune\n",
    "GFM_TO_TUNE = 'yangheng/OmniGenome-52M'\n",
    "\n",
    "# List of available GFMs for testing\n",
    "AVAILABLE_GFMS = [\n",
    "    'yangheng/OmniGenome-52M',\n",
    "    # 'yangheng/OmniGenome-186M',\n",
    "    # 'yangheng/OmniGenome-v1.5',\n",
    "    # 'zhihan1996/DNABERT-2-117M',\n",
    "    # 'LongSafari/hyenadna-large-1m-seqlen-hf',\n",
    "    # 'InstaDeepAI/nucleotide-transformer-v2-100m-multi-species',\n",
    "    # 'kuleshov-group/caduceus-ph_seqlen-131k_d_model-256_n_layer-16',\n",
    "    # 'multimolecule/rnafm',\n",
    "\n",
    "    # Evo models, you need to install the `evo` package according to the official documentation\n",
    "    # 'arcinstitute/evo-1-131k-base',\n",
    "    # 'SpliceBERT-510nt',\n",
    "]\n",
    "GFM = GFM_TO_TUNE.split('/')[-1]\n",
    "# --- LoRA Configuration ---\n",
    "# This dictionary contains LoRA settings for different models.\n",
    "# `r`: The rank of the update matrices.\n",
    "# `lora_alpha`: The scaling factor.\n",
    "# `lora_dropout`: The dropout probability for LoRA layers.\n",
    "# `target_modules`: The modules (e.g., attention blocks) to apply LoRA to.\n",
    "LORA_CONFIGS = {\n",
    "    \"OmniGenome-52M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"OmniGenome-186M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"caduceus-ph_seqlen-131k_d_model-256_n_layer-16\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"in_proj\", \"x_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnamsm\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnafm\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"rnabert\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"agro-nucleotide-transformer-1b\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"SpliceBERT-510nt\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"DNABERT-2-117M\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"Wqkv\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"3utrbert\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"hyenadna-large-1m-seqlen-hf\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"in_proj\", \"out_proj\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"nucleotide-transformer-v2-100m-multi-species\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"key\", \"value\", \"dense\"], \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1-131k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"mlp\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1.5-8k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo-1-8k-base\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "    \"evo2_7b\": {\n",
    "        \"r\": 8, \"lora_alpha\": 32, \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"Wqkv\", \"out_proj\",\n",
    "            \"l1\", \"l2\", \"l3\",\n",
    "            # \"projections\",\n",
    "            \"out_filter_dense\"\n",
    "        ],\n",
    "        \"bias\": \"none\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  - GFM to Tune: {GFM_TO_TUNE}\")\n",
    "print(f\"  - Benchmark: {BENCHMARK}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - LoRA Config: {LORA_CONFIGS.get(GFM, LORA_CONFIGS[GFM])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  - GFM to Tune: yangheng/OmniGenome-52M\n",
      "  - Benchmark: RGB\n",
      "  - Epochs: 1\n",
      "  - LoRA Config: {'r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['key', 'value', 'dense'], 'bias': 'none'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "89951b937ccc2cc2",
   "metadata": {},
   "source": [
    "## 4. Model-Specific Loading\n",
    "\n",
    "Different GFMs may require specific loading procedures. This function handles these special cases, particularly for models like `multimolecule` or `evo` which might have custom tokenizers or model classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "d2e1e3f7c5cd7901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:56:33.284424Z",
     "start_time": "2025-11-08T08:56:33.273607Z"
    }
   },
   "source": [
    "def load_gfm_and_tokenizer(gfm_name):\n",
    "    \"\"\"Loads a GFM and its tokenizer, handling special cases.\"\"\"\n",
    "    print(f\"\\nLoading model and tokenizer for: {gfm_name}\")\n",
    "    \n",
    "    if 'multimolecule' in gfm_name:\n",
    "        from multimolecule import RnaTokenizer, AutoModelForTokenPrediction\n",
    "        tokenizer = RnaTokenizer.from_pretrained(gfm_name)\n",
    "        model = AutoModelForTokenPrediction.from_pretrained(gfm_name, trust_remote_code=True).base_model\n",
    "        print(\"Loaded multimolecule model with custom classes.\")\n",
    "        \n",
    "    elif 'evo-1' in gfm_name:\n",
    "        # Using transformers to load Evo models\n",
    "        config = AutoConfig.from_pretrained(gfm_name, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(gfm_name, config=config, trust_remote_code=True).backbone\n",
    "        tokenizer = AutoTokenizer.from_pretrained(gfm_name, trust_remote_code=True)\n",
    "        tokenizer.pad_token_id = tokenizer.pad_token_type_id\n",
    "        \n",
    "        # Patch for the unembedding layer\n",
    "        model.config = config\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.unembed.unembed = lambda x: x\n",
    "        print(\"Loaded Evo model with custom patching.\")\n",
    "        \n",
    "    else:\n",
    "        # Default loading for most Hugging Face models\n",
    "        tokenizer = None  # Let AutoBench handle it\n",
    "        model = gfm_name\n",
    "        print(\"Using standard model name for AutoBench.\")\n",
    "        \n",
    "    return model, tokenizer\n",
    "\n",
    "print(\"Model loading function defined.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading function defined.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "43542679a9d3b7f9",
   "metadata": {},
   "source": [
    "## 5. Running LoRA Fine-tuning\n",
    "\n",
    "Now, we'll execute the LoRA fine-tuning process for the selected model. `AutoBench` handles the entire workflow, from data loading and preprocessing to training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "id": "818720a64f31f294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:56:52.975063Z",
     "start_time": "2025-11-08T08:56:35.752305Z"
    }
   },
   "source": [
    "# Load the selected model and tokenizer\n",
    "model, tokenizer = load_gfm_and_tokenizer(GFM_TO_TUNE)\n",
    "\n",
    "# Initialize AutoBench\n",
    "print(f\"\\nInitializing AutoBench for benchmark: {BENCHMARK}\")\n",
    "bench = AutoBench(\n",
    "    benchmark=BENCHMARK,\n",
    "    config_or_model=GFM_TO_TUNE,\n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True,\n",
    "    trainer='native',  # 'native' or 'accelerate'\n",
    "    autocast='fp16',  # 'fp16', 'bf16', or 'fp32'\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "# Get the appropriate LoRA config\n",
    "lora_config = LORA_CONFIGS.get(GFM, LORA_CONFIGS[GFM])\n",
    "\n",
    "# Run the benchmark with LoRA fine-tuning\n",
    "print(f\"\\nStarting LoRA fine-tuning for {GFM_TO_TUNE}...\")\n",
    "bench.run(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    patience=PATIENCE,\n",
    "    max_examples=MAX_EXAMPLES,\n",
    "    seeds=SEED,\n",
    "    epochs=EPOCHS,\n",
    "    lora_config=lora_config, # Pass the LoRA config here\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ LoRA fine-tuning complete!\")\n",
    "print(\"Check the 'autobench_logs' and 'autobench_evaluations' directories for results.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model and tokenizer for: yangheng/OmniGenome-52M\n",
      "Using standard model name for AutoBench.\n",
      "\n",
      "Initializing AutoBench for benchmark: RGB\n",
      "[2025-11-08 16:56:35.775] [omnigenbench 0.3.28alpha]  Benchmark: RGB cannot be found locally. Searching online hub to download...\n",
      "[2025-11-08 16:56:35.795] [omnigenbench 0.3.28alpha]  HuggingFace Hub API not available: No module named 'omnigenbench.src.model_hub'\n",
      "[2025-11-08 16:56:35.801] [omnigenbench 0.3.28alpha]  Install with: pip install huggingface_hub>=0.20.0\n",
      "[2025-11-08 16:56:35.808] [omnigenbench 0.3.28alpha]  Falling back to legacy HTTP download method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading benchmark: 33MB [00:10,  3.13MB/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-08 16:56:51.268] [omnigenbench 0.3.28alpha]  Benchmark RGB downloaded successfully to: __OMNIGENBENCH_DATA__/benchmarks/RGB.zip\n",
      "[2025-11-08 16:56:51.274] [omnigenbench 0.3.28alpha]  Unzipping checkpoint from __OMNIGENBENCH_DATA__/benchmarks/RGB.zip...\n",
      "[2025-11-08 16:56:52.099] [omnigenbench 0.3.28alpha]  Benchmark metadata version: 0.2.0alpha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\src\\misc\\utils.py:480: UserWarning: Benchmark version (0.2.0alpha) differs from OmniGenBench version (0.3.28alpha). This may cause compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-08 16:56:52.107] [omnigenbench 0.3.28alpha]  Loaded benchmarks:  ['RNA-mRNA', 'RNA-SNMD', 'RNA-SNMR', 'RNA-SSP-Archive2', 'RNA-SSP-rnastralign', 'RNA-SSP-bpRNA', 'RNA-TE-Prediction.Arabidopsis', 'RNA-TE-Prediction.Rice', 'RNA-Region-Classification.Arabidopsis', 'RNA-Region-Classification.Rice']\n",
      "[2025-11-08 16:56:52.117] [omnigenbench 0.3.28alpha]  Benchmark Root: __OMNIGENBENCH_DATA__/benchmarks/RGB\n",
      "Benchmark List: ['RNA-mRNA', 'RNA-SNMD', 'RNA-SNMR', 'RNA-SSP-Archive2', 'RNA-SSP-rnastralign', 'RNA-SSP-bpRNA', 'RNA-TE-Prediction.Arabidopsis', 'RNA-TE-Prediction.Rice', 'RNA-Region-Classification.Arabidopsis', 'RNA-Region-Classification.Rice']\n",
      "Model Name or Path: OmniGenome-52M\n",
      "Tokenizer: None\n",
      "Metric Visualizer Path: ./autobench_evaluations/RGB-OmniGenome-52M-20251108_165635.mv\n",
      "BenchConfig Details: <module 'bench_metadata' from 'D:\\\\OneDrive - University of Exeter\\\\AIProjects\\\\OmniGenBench\\\\examples\\\\autobench_gfm_evaluation\\\\__OMNIGENBENCH_DATA__/benchmarks/RGB/metadata.py'>\n",
      "\n",
      "\n",
      "Starting LoRA fine-tuning for yangheng/OmniGenome-52M...\n",
      "[2025-11-08 16:56:52.137] [omnigenbench 0.3.28alpha]  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \n",
      "Running evaluation for task: RNA-mRNA Progress:  1 / 10 10.0%\n",
      "FindFile Warning --> multiple targets ['__OMNIGENBENCH_DATA__/benchmarks/RGB\\\\RNA-mRNA\\\\config.py', '__OMNIGENBENCH_DATA__/benchmarks/RGB\\\\RNA-mRNA\\\\__pycache__\\\\config.cpython-312.pyc', '__OMNIGENBENCH_DATA__/benchmarks/RGB\\\\RNA-mRNA\\\\__pycache__\\\\config.cpython-39.pyc'] found, only return the shortest path: <__OMNIGENBENCH_DATA__/benchmarks/RGB\\RNA-mRNA\\config.py>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenome\\__init__.py:30: DeprecationWarning: The 'omnigenome' package is deprecated, please use omnigenbench package instead. e.g., from omnigenbench import  *  ->  from omnigenbench import *\n",
      "All imports from omnigenome will be redirected to omnigenbench. \n",
      "  warnings.warn(\n",
      "D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenome\\__init__.py:242: ImportWarning: Failed to import omnigenbench modules: cannot import name 'load_benchmark_datasets' from 'omnigenbench.src.utility.dataset_hub' (D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\src\\utility\\dataset_hub\\__init__.py). Please ensure omnigenbench is properly installed.\n",
      "You can install it with: pip install omnigenbench\n",
      "and replace all 'omnigenome' with 'omnigenbench' in your code.\n",
      "e.g., from omnigenbench import  *  ->  from omnigenbench import *\n",
      "  warnings.warn(\n",
      "D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\src\\misc\\utils.py:370: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoBenchConfig' from 'omnigenome' (D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenome\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# Run the benchmark with LoRA fine-tuning\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mStarting LoRA fine-tuning for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mGFM_TO_TUNE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[43mbench\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPATIENCE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_examples\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMAX_EXAMPLES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[43mseeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mSEED\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlora_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlora_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Pass the LoRA config here\u001B[39;49;00m\n\u001B[32m     29\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33müéâ LoRA fine-tuning complete!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     32\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mCheck the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mautobench_logs\u001B[39m\u001B[33m'\u001B[39m\u001B[33m and \u001B[39m\u001B[33m'\u001B[39m\u001B[33mautobench_evaluations\u001B[39m\u001B[33m'\u001B[39m\u001B[33m directories for results.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\auto\\auto_bench\\auto_bench.py:230\u001B[39m, in \u001B[36mAutoBench.run\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    217\u001B[39m fprint(\n\u001B[32m    218\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m>\u001B[39m\u001B[33m\"\u001B[39m * \u001B[32m80\u001B[39m,\n\u001B[32m    219\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mRunning evaluation for task: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbench\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    224\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(_\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m)\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[32m100\u001B[39m\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.bench_metadata.bench_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m%\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    225\u001B[39m )\n\u001B[32m    226\u001B[39m bench_config_path = findfile.find_file(\n\u001B[32m    227\u001B[39m     \u001B[38;5;28mself\u001B[39m.benchmark,\n\u001B[32m    228\u001B[39m     and_key=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.benchmark\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbench\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.config\u001B[39m\u001B[33m\"\u001B[39m.split(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m    229\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m230\u001B[39m config = \u001B[43mload_module_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mconfig\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbench_config_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m bench_config = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    232\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m attr_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mdir\u001B[39m(config):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenbench\\src\\misc\\utils.py:460\u001B[39m, in \u001B[36mload_module_from_path\u001B[39m\u001B[34m(module_name, file_path)\u001B[39m\n\u001B[32m    458\u001B[39m spec = importlib.util.spec_from_file_location(module_name, file_path)\n\u001B[32m    459\u001B[39m module = importlib.util.module_from_spec(spec)\n\u001B[32m--> \u001B[39m\u001B[32m460\u001B[39m \u001B[43mspec\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexec_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m module\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:1026\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:488\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\examples\\autobench_gfm_evaluation\\__OMNIGENBENCH_DATA__/benchmarks/RGB\\RNA-mRNA\\config.py:16\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01momnigenome\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     17\u001B[39m     AutoBenchConfig,\n\u001B[32m     18\u001B[39m     OmniGenomeDatasetForTokenRegression,\n\u001B[32m     19\u001B[39m     OmniGenomeModelForTokenRegression,\n\u001B[32m     20\u001B[39m     RegressionMetric,\n\u001B[32m     21\u001B[39m )\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mDataset\u001B[39;00m(OmniGenomeDatasetForTokenRegression):\n\u001B[32m     25\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_name_or_path, tokenizer, max_length, **kwargs):\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'AutoBenchConfig' from 'omnigenome' (D:\\OneDrive - University of Exeter\\AIProjects\\OmniGenBench\\omnigenome\\__init__.py)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "386249fc8fc35efa",
   "metadata": {},
   "source": [
    "## 6. Multi-Model LoRA Fine-tuning (Optional)\n",
    "\n",
    "The following section demonstrates how to automate the LoRA fine-tuning process for a list of GFMs. Uncomment and run this cell to compare the performance of multiple models with LoRA."
   ]
  },
  {
   "cell_type": "code",
   "id": "7f89dd9373b6a3a7",
   "metadata": {},
   "source": [
    "# # Uncomment this cell to run LoRA fine-tuning for multiple models\n",
    "\n",
    "# print(\"Starting multi-model LoRA fine-tuning...\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# for gfm in AVAILABLE_GFMS:\n",
    "#     try:\n",
    "#         # Load model and tokenizer\n",
    "#         model, tokenizer = load_gfm_and_tokenizer(gfm)\n",
    "\n",
    "#         # Initialize AutoBench\n",
    "#         print(f\"\\nInitializing AutoBench for {gfm} on {BENCHMARK}\")\n",
    "#         bench = AutoBench(\n",
    "#             benchmark=BENCHMARK,\n",
    "#             config_or_model=model,\n",
    "#             tokenizer=tokenizer,\n",
    "#             overwrite=True,\n",
    "#             trainer='native',\n",
    "#             autocast='fp16',\n",
    "#             device='cuda',\n",
    "#         )\n",
    "\n",
    "#         # Get the appropriate LoRA config\n",
    "#         lora_config = LORA_CONFIGS.get(gfm.split('/')[-1], LORA_CONFIGS['default'])\n",
    "\n",
    "#         # Run the benchmark\n",
    "#         print(f\"\\nStarting LoRA fine-tuning for {gfm}...\")\n",
    "#         bench.run(\n",
    "#             batch_size=BATCH_SIZE,\n",
    "#             patience=PATIENCE,\n",
    "#             max_examples=MAX_EXAMPLES,\n",
    "#             seeds=SEED,\n",
    "#             epochs=EPOCHS,\n",
    "#             lora_config=lora_config,\n",
    "#         )\n",
    "#         print(f\"\\n‚úÖ Finished fine-tuning for {gfm}.\")\n",
    "#         print(\"=\"*50)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n‚ùå An error occurred while processing {gfm}: {e}\")\n",
    "#         print(\"=\"*50)\n",
    "#         continue\n",
    "\n",
    "# print(\"\\nüéâ All models have been processed!\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
