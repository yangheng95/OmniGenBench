{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u001F TFB Prediction Tutorial 3/4: Model Training - Teaching the Model to Predict\n",
    "\n",
    "Welcome to the third tutorial in our series. So far, we have:\n",
    "1.  Prepared our dataset and dataloaders ([01_data_preparation.ipynb](https://github.com/yangheng95/OmniGenBench/blob/master/examples/tfb_prediction/01_data_preparation.ipynb)).\n",
    "2.  Selected and initialized the correct model architecture ([02_model_initialization.ipynb](https://github.com/yangheng95/OmniGenBench/blob/master/examples/tfb_prediction/02_model_initialization.ipynb)).\n",
    "\n",
    "Now, we have all the ingredients ready. In this tutorial, we will combine them to **train** the model. Training is the process of teaching the model to make accurate predictions by showing it examples from our dataset and adjusting its internal parameters.\n",
    "\n",
    "This tutorial will cover:\n",
    "1.  **The Concept of Supervised Training**: What it means to train a model and what components are required.\n",
    "2.  **Trainers in `OmniGenBench`**: An overview of the different training engines available in the framework.\n",
    "3.  **The Training Process in Action**: A step-by-step guide to configuring and launching the training job.\n",
    "4.  **Evaluation and Results**: How we measure the model's performance and what artifacts are produced.\n",
    "\n",
    "By the end of this tutorial, you will have a fine-tuned model saved on your disk, ready for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Concept of Supervised Training\n",
    "\n",
    "At its heart, **supervised training** is like teaching a student with a textbook and an answer key. We show the model an input (a DNA sequence), let it make a prediction, and then compare its prediction to the correct answer (the labels). The difference between the prediction and the answer is quantified by a **loss function**. The goal is to minimize this loss.\n",
    "\n",
    "This process is iterative and happens in a **training loop**, which consists of four main steps:\n",
    "1.  **Forward Pass**: The input data is passed through the model to get a prediction.\n",
    "2.  **Loss Calculation**: The model's prediction is compared to the ground-truth labels using a loss function (e.g., Binary Cross-Entropy for our task).\n",
    "3.  **Backward Pass (Backpropagation)**: The loss is used to calculate the gradient for each of the model's parameters. The gradient tells us how to adjust each parameter to reduce the loss.\n",
    "4.  **Optimizer Step**: An **optimizer** (like AdamW) updates the model's parameters based on the calculated gradients.\n",
    "\n",
    "To manage this entire process, we need a few key components:\n",
    "-   A **Model** to be trained.\n",
    "-   **DataLoaders** to supply batches of data for training, validation, and testing.\n",
    "-   A **Loss Function** to measure prediction error.\n",
    "-   An **Optimizer** to update the model's weights.\n",
    "-   An **Evaluation Metric** (e.g., ROC-AUC) to assess performance on a validation set.\n",
    "\n",
    "A **Trainer** is an object that encapsulates this entire training loop, abstracting away the boilerplate code and providing a clean interface to manage training, evaluation, and logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Trainers in `OmniGenBench`\n",
    "\n",
    "`OmniGenBench` provides a flexible system for training by offering several \"Trainer\" classes, each suited for different needs. All trainers handle the core training loop, but they differ in their features and complexity.\n",
    "\n",
    "| Trainer Class         | Key Feature                               | When to Use                                                                                             |\n",
    "| --------------------- | ----------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| `Trainer`             | Native PyTorch Implementation             | For simple, single-GPU training. It's lightweight and gives you a clear, direct PyTorch experience.      |\n",
    "| `AccelerateTrainer`   | Distributed Training via `accelerate`     | **Recommended for most users.** Easily scales from single-GPU to multi-GPU or multi-node setups with minimal code changes. |\n",
    "| `HFTrainer`           | Integration with Hugging Face `Trainer`   | If you are already heavily invested in the Hugging Face ecosystem and prefer its `TrainingArguments` setup. |\n",
    "\n",
    "For this tutorial, we will use the **`AccelerateTrainer`**. It represents the best balance of power and ease of use, making it simple to run our experiment on a single GPU today and scale it up to a powerful cluster tomorrow if needed. The `accelerate` library by Hugging Face handles all the complexities of distributed training behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The Training Process in Action\n",
    "\n",
    "Let's put everything together and train our model. The process involves three main code blocks:\n",
    "1.  **Re-establishing the context**: We'll quickly re-run the code from the previous tutorials to get our `dataloaders`, `model`, and `tokenizer`.\n",
    "2.  **Defining the evaluation metric**: We'll set up the function to compute ROC-AUC during validation.\n",
    "3.  **Configuring and running the `AccelerateTrainer`**: This is where we define all training parameters and launch the job.\n",
    "\n",
    "#### 3.1. Setup: Data and Model Initialization\n",
    "\n",
    "First, let's import everything we need and run the setup code from the previous tutorials. This ensures we have all the necessary objects in our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries - matches complete tutorial\n",
    "import torch\n",
    "from omnigenbench import (\n",
    "    OmniTokenizer,\n",
    "    OmniModelForMultiLabelSequenceClassification,\n",
    "    OmniDatasetForMultiLabelClassification,\n",
    "    ClassificationMetric,\n",
    "    AccelerateTrainer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéØ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - matches complete tutorial exactly  \n",
    "model_name_or_path = \"yangheng/OmniGenome-52M\"\n",
    "dataset_name = \"deepsea_tfb_prediction\"\n",
    "\n",
    "# Basic training parameters\n",
    "num_labels = 919\n",
    "max_length = 512\n",
    "batch_size = 64\n",
    "learning_rate = 2e-5\n",
    "epochs = 3\n",
    "output_dir = \"./ogb_tfb_finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and prepare datasets - matches complete tutorial\n",
    "print(\"üîÑ Loading tokenizer...\")\n",
    "tokenizer = OmniTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "print(\"üìä Loading DeepSEA TFB dataset...\")\n",
    "datasets = OmniDatasetForMultiLabelClassification.from_hub(\n",
    "    dataset_name_or_path=dataset_name,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    max_examples=1000,  # For quick testing; set to None for full dataset\n",
    "    force_padding=False\n",
    ")\n",
    "\n",
    "print(f\"üìã Dataset prepared:\")\n",
    "print(f\"  üìà Training samples: {len(datasets['train'])}\")\n",
    "print(f\"  üîç Validation samples: {len(datasets['valid'])}\")\n",
    "print(f\"  üß™ Test samples: {len(datasets['test'])}\")\n",
    "\n",
    "# Initialize model - matches complete tutorial\n",
    "print(\"üîÑ Loading model...\")\n",
    "model = OmniModelForMultiLabelSequenceClassification(\n",
    "    model_name_or_path,\n",
    "    tokenizer,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ Model loaded with {num_labels} labels!\")\n",
    "print(f\"üìä Parameters: {total_params / 1e6:.1f}M\")\n",
    "print(\"‚úÖ Training setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove this cell as it duplicates the setup above and has incorrect variable references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Defining the Evaluation Metric\n",
    "\n",
    "During training, we need to monitor how well our model is performing on data it hasn't seen before (the validation set). This helps us avoid overfitting and tells us when to stop training. For multi-label classification tasks, **Area Under the Receiver Operating Characteristic Curve (ROC-AUC)** is a standard and robust metric.\n",
    "\n",
    "We will define a `compute_metrics` function that takes the model's predictions and the true labels and returns the average ROC-AUC score across all labels. The `AccelerateTrainer` will automatically call this function at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup evaluation metrics - matches complete tutorial\n",
    "print(\"üìä Setting up evaluation metrics...\")\n",
    "\n",
    "# Use the ClassificationMetric from OmniGenBench\n",
    "metric_functions = [ClassificationMetric(ignore_y=-100).roc_auc_score]\n",
    "\n",
    "print(\"‚úÖ Metrics configured:\")\n",
    "print(\"   üìà ROC-AUC score for multi-label classification\")\n",
    "print(\"   üéØ Measures model's ability to distinguish between classes\")\n",
    "print(\"   üìä Averages across all 919 TF labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Configuring and Running the `AccelerateTrainer`\n",
    "\n",
    "This is the final and most important step. We will instantiate the `AccelerateTrainer` and provide it with all the necessary components and hyperparameters.\n",
    "\n",
    "Key parameters for the trainer include:\n",
    "-   `model`, `train_dataloader`, `valid_dataloader`: The core components for training.\n",
    "-   `epochs`: The total number of times to iterate over the entire training dataset.\n",
    "-   `optimizer_class`: The optimizer to use (we'll use `torch.optim.AdamW`, a standard choice for transformer models).\n",
    "-   `lr`: The learning rate, which controls the step size of the optimizer.\n",
    "-   `compute_metrics`: Our evaluation function.\n",
    "-   `output_dir`: The directory where checkpoints and results will be saved.\n",
    "-   `early_stopping_patience`: A crucial parameter for preventing overfitting. The training will stop if the validation metric (`roc_auc`) does not improve for this many epochs.\n",
    "-   `monitor_metric`: The metric to watch for early stopping and for saving the best model checkpoint.\n",
    "\n",
    "Let's create the trainer and start the training process by calling the `.train()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the AccelerateTrainer - matches complete tutorial exactly\n",
    "print(\"üöÄ Setting up AccelerateTrainer...\")\n",
    "\n",
    "trainer = AccelerateTrainer(\n",
    "    model=model,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"valid\"],\n",
    "    test_dataset=datasets[\"test\"],\n",
    "    compute_metrics=metric_functions,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"üéì Starting training...\")\n",
    "metrics = trainer.train()\n",
    "trainer.save_model(\"ogb_tfb_finetuned\")\n",
    "\n",
    "print('Metrics:', metrics)\n",
    "print(\"‚úÖ Training finished!\")\n",
    "print(f\"üíæ Model saved as: ogb_tfb_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Next Steps\n",
    "\n",
    "In this tutorial, we have successfully fine-tuned our Genomic Foundation Model for the task of TFB prediction.\n",
    "\n",
    "We have learned about:\n",
    "-   The core concepts of supervised training.\n",
    "-   The different trainers available in `OmniGenBench` and why `AccelerateTrainer` is a good choice.\n",
    "-   How to configure and launch a training job, including setting up an evaluation metric and early stopping.\n",
    "-   The outputs of the training process: a trained model checkpoint (`best_model.pth`) and a results summary (`all_results.json`).\n",
    "\n",
    "We now have a model that has learned to identify transcription factor binding sites from raw DNA sequences. But a trained model is only useful if we can use it to make predictions on new, unseen data.\n",
    "\n",
    "In the final tutorial of this series, **[4/4: Model Inference](./04_model_inference.ipynb)**, we will learn how to load our saved model and use it to perform inference, evaluate its performance on the test set, and interpret the results."
   ]
  }
 ],
 "metadata": {
  "bytes": "bb47106096b6419d9ad92ef1315e2393",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
