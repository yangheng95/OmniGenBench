{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738cc335",
   "metadata": {},
   "source": [
    "# üîç Attention Analysis Tutorial: Exploring Genomic Attention Patterns\n",
    "\n",
    "## üéØ Key Feature: ALL OmniModel Types Support Attention Extraction!\n",
    "\n",
    "This tutorial demonstrates attention extraction capabilities that are now available in **ALL OmniGenBench models** through the `EmbeddingMixin`.\n",
    "\n",
    "### Supported Model Types\n",
    "‚úÖ `OmniModelForEmbedding` - Dedicated embedding extraction  \n",
    "‚úÖ `OmniModelForSequenceClassification` - Classification + Attention  \n",
    "‚úÖ `OmniModelForSequenceRegression` - Regression + Attention  \n",
    "‚úÖ `OmniModelForTokenClassification` - Token classification + Attention  \n",
    "‚úÖ `OmniModelForMLM` - Masked language modeling + Attention  \n",
    "‚úÖ **All other OmniModel variants** - Task-specific + Attention\n",
    "\n",
    "### What You'll Learn\n",
    "1. üß¨ Extract attention scores from genomic sequences\n",
    "2. üìä Analyze attention patterns and statistics\n",
    "3. üé® Visualize attention heatmaps\n",
    "4. üî¨ Compare attention patterns across sequences\n",
    "5. üí° Use attention extraction with any model type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b94775",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6771630",
   "metadata": {},
   "source": [
    "!pip install omnigenbench -U -q"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "62511985",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "80008fd5",
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Import various model types - ALL support attention extraction!\n",
    "from omnigenbench import (\n",
    "    OmniModelForEmbedding,\n",
    "    OmniModelForSequenceClassification,\n",
    "    OmniModelForSequenceRegression,\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(\"üí° All OmniModel types support attention extraction!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef397b99",
   "metadata": {},
   "source": [
    "## üîß Load Model\n",
    "\n",
    "### Important: You Can Use ANY OmniModel Type!\n",
    "\n",
    "The attention extraction functionality is available in all model types. Choose the one that fits your use case:\n",
    "- Use `OmniModelForEmbedding` for dedicated embedding/attention extraction\n",
    "- Use `OmniModelForSequenceClassification` if you also need classification\n",
    "- Use `OmniModelForSequenceRegression` if you also need regression\n",
    "- And so on..."
   ]
  },
  {
   "cell_type": "code",
   "id": "05b48e8c",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "model_name = \"yangheng/OmniGenome-186M\"  # Change to your preferred model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"üîß Loading model: {model_name}\")\n",
    "print(f\"üì± Device: {device}\")\n",
    "\n",
    "# Option 1: Use dedicated embedding model\n",
    "model = OmniModelForEmbedding(model_name, trust_remote_code=True)\n",
    "\n",
    "# Option 2: Use classification model (also supports attention extraction!)\n",
    "# model = OmniModelForSequenceClassification(\n",
    "#     model=model_name,\n",
    "#     num_labels=2,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# Option 3: Use regression model (also supports attention extraction!)\n",
    "# model = OmniModelForSequenceRegression(\n",
    "#     model=model_name,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {type(model).__name__}\")\n",
    "print(f\"üí° This model supports both task-specific operations AND attention extraction!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "794fa5ca",
   "metadata": {},
   "source": [
    "## üß¨ Prepare Test Sequences"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8dcb4a3",
   "metadata": {},
   "source": [
    "# Example genomic sequences with different characteristics\n",
    "test_sequences = [\n",
    "    \"ATCGATCGATCGTAGCTAGCTAGCT\",  # Regular sequence\n",
    "    \"GGCCTTAACCGGTTAACCGGTTAA\",   # GC-rich sequence\n",
    "    \"TTTTAAAACCCCGGGGTTTTAAAA\",   # Repeat pattern\n",
    "    \"AUGCGAUCUCGAGCUACGUCGAUGCUAGCUCGAUGGCAUCCGAUUCGAGCUACGUCGAUGCUAG\",  # Longer sequence\n",
    "]\n",
    "\n",
    "print(\"üß¨ Test sequences prepared:\")\n",
    "for i, seq in enumerate(test_sequences, 1):\n",
    "    print(f\"  {i}. {seq[:40]}{'...' if len(seq) > 40 else ''}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a7291392",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Extract Attention Scores from Single Sequence"
   ]
  },
  {
   "cell_type": "code",
   "id": "9481c2f3",
   "metadata": {},
   "source": [
    "# Extract attention from the first sequence\n",
    "sequence = test_sequences[0]\n",
    "\n",
    "print(f\"üîç Analyzing sequence: {sequence}\")\n",
    "print(\"‚è≥ Extracting attention scores...\")\n",
    "\n",
    "attention_result = model.extract_attention_scores(\n",
    "    sequence=sequence,\n",
    "    max_length=128,\n",
    "    layer_indices=None,  # Extract all layers (or specify [0, 5, 11] for specific layers)\n",
    "    head_indices=None,   # Extract all heads (or specify [0, 1, 2] for specific heads)\n",
    "    return_on_cpu=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Attention extraction successful!\")\n",
    "print(f\"üìä Attention tensor shape: {attention_result['attentions'].shape}\")\n",
    "print(f\"   Format: (layers, heads, seq_len, seq_len)\")\n",
    "print(f\"üî§ Number of tokens: {len(attention_result['tokens'])}\")\n",
    "print(f\"üéØ First 10 tokens: {attention_result['tokens'][:10]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b0aedf1",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Compute Attention Statistics"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f297324",
   "metadata": {},
   "source": [
    "# Compute comprehensive attention statistics\n",
    "stats = model.get_attention_statistics(\n",
    "    attention_result['attentions'],\n",
    "    attention_result['attention_mask'],\n",
    "    layer_aggregation=\"mean\",  # Options: mean, max, sum, first, last\n",
    "    head_aggregation=\"mean\"    # Options: mean, max, sum\n",
    ")\n",
    "\n",
    "print(\"üìà Attention Statistics:\")\n",
    "print(f\"  Attention matrix shape: {stats['attention_matrix'].shape}\")\n",
    "print(f\"  Average attention entropy: {stats['attention_entropy'].mean():.4f}\")\n",
    "print(f\"  Max attention concentration: {stats['attention_concentration'].max():.4f}\")\n",
    "print(f\"  Average self-attention score: {stats['self_attention_scores'].mean():.4f}\")\n",
    "print(f\"  Max attention per position (top 5): {stats['max_attention_per_position'][:5]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acf2e7cc",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Visualize Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3376a28",
   "metadata": {},
   "source": [
    "# Visualize attention pattern for a specific layer and head\n",
    "fig = model.visualize_attention_pattern(\n",
    "    attention_result=attention_result,\n",
    "    layer_idx=0,   # First layer\n",
    "    head_idx=0,    # First attention head\n",
    "    save_path=\"attention_heatmap.png\",\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "\n",
    "if fig is not None:\n",
    "    print(\"‚úÖ Attention heatmap generated and saved!\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Visualization skipped (matplotlib not available)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7c003db7",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Batch Attention Extraction"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ab9059f",
   "metadata": {},
   "source": [
    "# Extract attention from multiple sequences efficiently\n",
    "print(\"‚è≥ Extracting attention from batch of sequences...\")\n",
    "\n",
    "batch_results = model.batch_extract_attention_scores(\n",
    "    sequences=test_sequences[:3],  # First 3 sequences\n",
    "    batch_size=2,\n",
    "    max_length=128,\n",
    "    layer_indices=[0, -1],  # First and last layer only\n",
    "    head_indices=[0, 1, 2], # First 3 heads only\n",
    "    return_on_cpu=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Batch attention extraction successful!\")\n",
    "print(f\"üìä Processed {len(batch_results)} sequences\")\n",
    "\n",
    "for i, result in enumerate(batch_results, 1):\n",
    "    print(f\"  Sequence {i} attention shape: {result['attentions'].shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a7a648a",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Compare Attention Patterns Across Sequences"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3d4249c",
   "metadata": {},
   "source": [
    "# Compare attention patterns between different sequences\n",
    "print(\"üî¨ Comparing attention patterns across sequences...\\n\")\n",
    "\n",
    "for i, result in enumerate(batch_results, 1):\n",
    "    stats = model.get_attention_statistics(\n",
    "        result['attentions'],\n",
    "        result['attention_mask']\n",
    "    )\n",
    "    \n",
    "    seq_preview = test_sequences[i-1][:30] + \"...\"\n",
    "    print(f\"Sequence {i}: {seq_preview}\")\n",
    "    print(f\"  Attention entropy: {stats['attention_entropy'].mean():.4f}\")\n",
    "    print(f\"  Self-attention: {stats['self_attention_scores'].mean():.4f}\")\n",
    "    print(f\"  Concentration: {stats['attention_concentration'].mean():.4f}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "291b81ae",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Advanced: Embedding Extraction\n",
    "\n",
    "### Bonus: Extract Embeddings Too!\n",
    "\n",
    "Since all OmniModel types support both attention AND embedding extraction, you can easily get both:"
   ]
  },
  {
   "cell_type": "code",
   "id": "80add529",
   "metadata": {},
   "source": [
    "# Extract embeddings from the same model\n",
    "print(\"üéØ Extracting embeddings from the same model...\")\n",
    "\n",
    "# Single sequence\n",
    "embedding = model.encode(test_sequences[0], agg=\"mean\")\n",
    "print(f\"Single embedding shape: {embedding.shape}\")\n",
    "\n",
    "# Batch encoding\n",
    "embeddings = model.batch_encode(test_sequences, batch_size=4, agg=\"mean\")\n",
    "print(f\"Batch embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Compute similarity\n",
    "similarity = model.compute_similarity(embeddings[0], embeddings[1])\n",
    "print(f\"\\nSimilarity between sequences 1 and 2: {similarity:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Both attention and embeddings extracted from the same model!\")\n",
    "print(\"üí° This works with ALL OmniModel types!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9163e4e",
   "metadata": {},
   "source": [
    "## üéâ Summary\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Universal Support**: ALL OmniModel types support attention and embedding extraction\n",
    "2. **Flexible API**: Same API works across all model types\n",
    "3. **Rich Features**:\n",
    "   - `extract_attention_scores()` - Single sequence attention\n",
    "   - `batch_extract_attention_scores()` - Batch processing\n",
    "   - `get_attention_statistics()` - Attention analysis\n",
    "   - `visualize_attention_pattern()` - Visualization\n",
    "   - `encode()` / `batch_encode()` - Embedding extraction\n",
    "   - `compute_similarity()` - Similarity computation\n",
    "\n",
    "### Supported Model Types\n",
    "‚úÖ OmniModelForEmbedding  \n",
    "‚úÖ OmniModelForSequenceClassification  \n",
    "‚úÖ OmniModelForSequenceRegression  \n",
    "‚úÖ OmniModelForTokenClassification  \n",
    "‚úÖ OmniModelForMLM  \n",
    "‚úÖ All other OmniModel variants!\n",
    "\n",
    "### Key Benefits\n",
    "- üéØ Use task-specific models for their intended purpose\n",
    "- üîç Extract attention and embeddings from the same model\n",
    "- üí™ No need for separate embedding models\n",
    "- üöÄ Efficient and unified API\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**: Try using attention extraction with your fine-tuned models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
